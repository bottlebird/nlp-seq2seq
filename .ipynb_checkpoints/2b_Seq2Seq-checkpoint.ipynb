{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FU7xWiY6TyWS"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
    "rm -rf 6864-hw2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uie6jWpIhg_B"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5AyMA9rK1Rhf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"6864-hw2b\", exist_ok=True)\n",
    "import sys\n",
    "sys.path.append(\"/content/6864-hw2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7120,
     "status": "ok",
     "timestamp": 1587835622744,
     "user": {
      "displayName": "ByeongJo Kong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64",
      "userId": "10931837966081205326"
     },
     "user_tz": 240
    },
    "id": "BL1IfnRdPdsl",
    "outputId": "4f4398f7-5a5f-4fb6-81fe-44c69f7ab082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacrebleu\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/27/e9c95f45fc11f9093000d234564823aab762f517458f1aa1ad01ba51d5f2/sacrebleu-1.4.7-py3-none-any.whl (59kB)\n",
      "\r",
      "\u001b[K     |█████▌                          | 10kB 21.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 20kB 2.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 30kB 2.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 40kB 2.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 51kB 2.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 61kB 2.1MB/s \n",
      "\u001b[?25hCollecting portalocker\n",
      "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
      "Collecting mecab-python3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/49/b55a839a77189042960bf96490640c44816073f917d489acbc5d79fa5cc3/mecab_python3-0.996.5-cp36-cp36m-manylinux2010_x86_64.whl (17.1MB)\n",
      "\u001b[K     |████████████████████████████████| 17.1MB 1.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n",
      "Installing collected packages: portalocker, mecab-python3, sacrebleu\n",
      "Successfully installed mecab-python3-0.996.5 portalocker-1.7.0 sacrebleu-1.4.7\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5fOArV2r9Piz"
   },
   "source": [
    "# **Part 3: Sequence-to-Sequence Model**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mA9JfWiK9eoL"
   },
   "source": [
    "In this lab, you will explore RNN-based sequence-to-sequence (seq2seq) models to perform machine translation (MT). We will use a Vietnamese-English dataset from IWSLT'15. The task is to translate a Vietnamese sentence into English.\n",
    "\n",
    "The lab is divided into two parts. The first part is to implement a vanilla seq2seq architecture without attention. In the second part you will implement your favorite attention mechanism (doesn't have to come from lecture) and add it to your vanilla seq2seq model. We will provide the training and testing scripts (trust me, the decoding/testing is actually the hardest part :P), so you will mainly just have to focus on implementing the models (I say *mainly* because you still might need to modify the testing script, depending on which attention method you use and how you implement it).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zDJjmvZfHV_l"
   },
   "source": [
    "## **Section 1: Data Preprocessing**\n",
    "\n",
    "No need to write any code in this section. But you are encouraged to test with this part to understand the data.\n",
    "\n",
    "First, we download the dataset and place it under current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7575,
     "status": "ok",
     "timestamp": 1587835633421,
     "user": {
      "displayName": "ByeongJo Kong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64",
      "userId": "10931837966081205326"
     },
     "user_tz": 240
    },
    "id": "02RioHPryvOz",
    "outputId": "862e370c-f45d-4103-e61a-e29944dae40c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-25 17:27:07 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en [13603614/13603614] -> \"/content/6864-hw2b/train.en\" [1]\n",
      "2020-04-25 17:27:09 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi [18074646/18074646] -> \"/content/6864-hw2b/train.vi\" [1]\n",
      "2020-04-25 17:27:10 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en [132264/132264] -> \"/content/6864-hw2b/tst2013.en\" [1]\n",
      "2020-04-25 17:27:11 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi [183855/183855] -> \"/content/6864-hw2b/tst2013.vi\" [1]\n",
      "2020-04-25 17:27:12 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.en [139741/139741] -> \"/content/6864-hw2b/vocab.en\" [1]\n",
      "2020-04-25 17:27:12 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.vi [46767/46767] -> \"/content/6864-hw2b/vocab.vi\" [1]\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "!wget -nv -O /content/6864-hw2b/train.en https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en\n",
    "!wget -nv -O /content/6864-hw2b/train.vi https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi\n",
    "!wget -nv -O /content/6864-hw2b/tst2013.en https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en\n",
    "!wget -nv -O /content/6864-hw2b/tst2013.vi https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi\n",
    "!wget -nv -O /content/6864-hw2b/vocab.en https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.en\n",
    "!wget -nv -O /content/6864-hw2b/vocab.vi https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.vi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ogFESHAf-6MY"
   },
   "source": [
    "Next, we do some simple data preprocessing and show some data statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2253,
     "status": "ok",
     "timestamp": 1587835637651,
     "user": {
      "displayName": "ByeongJo Kong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64",
      "userId": "10931837966081205326"
     },
     "user_tz": 240
    },
    "id": "OfkQGqV30hgC",
    "outputId": "45e5d7fd-b304-4a0c-a32c-5bfc363b87db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training (src, trg) sentence pairs: 108748\n",
      "Number of validation (src, trg) sentence pairs: 12083\n",
      "Number of testing (src, trg) sentence pairs: 1139\n",
      "Size of en vocab set (including '<pad>', '<unk>', '<s>', '</s>'): 7710\n",
      "Size of vi vocab set (including '<pad>', '<unk>', '<s>', '</s>'): 17192\n",
      "Training sentence avg. length: 20 \n",
      "Training sentence length at 95-percentile: 42\n",
      "Training sentence length distribution (x-axis is length range and y-axis is count):\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Vietnamese input: ['Adam', 'Sadowsky', 'dàn', 'dựng', '1', 'video', 'âm', 'nhạc', 'hiện', 'tượng', '.']\n",
      "Its target English output: ['Adam', 'Sadowsky', ':', 'How', 'to', 'engineer', 'a', 'viral', 'music', 'video']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def read_sentence_file(filename):\n",
    "  sentences_list = []\n",
    "  with open(filename, \"r\") as f:\n",
    "    for line in f:\n",
    "      sentences_list.append(line.strip().split())\n",
    "  return sentences_list\n",
    "\n",
    "def read_vocab_file(filename):\n",
    "  with open(filename, \"r\") as f:\n",
    "    return [line.strip() for line in f]\n",
    "\n",
    "\n",
    "src_vocab_set = read_vocab_file(os.path.join(\"/content/6864-hw2b\", \"vocab.vi\"))\n",
    "trg_vocab_set = read_vocab_file(os.path.join(\"/content/6864-hw2b\", \"vocab.en\"))\n",
    "\n",
    "train_src_sentences_list = read_sentence_file(os.path.join(\"/content/6864-hw2b\",\n",
    "                                                           \"train.vi\"))\n",
    "train_trg_sentences_list = read_sentence_file(os.path.join(\"/content/6864-hw2b\",\n",
    "                                                           \"train.en\"))\n",
    "assert len(train_src_sentences_list) == len(train_trg_sentences_list)\n",
    "\n",
    "test_src_sentences_list = read_sentence_file(os.path.join(\"/content/6864-hw2b\",\n",
    "                                                          \"tst2013.vi\"))\n",
    "test_trg_sentences_list = read_sentence_file(os.path.join(\"/content/6864-hw2b\",\n",
    "                                                          \"tst2013.en\"))\n",
    "assert len(test_src_sentences_list) == len(test_trg_sentences_list)\n",
    "\n",
    "\n",
    "MAX_SENT_LENGTH = 48\n",
    "MAX_SENT_LENGTH_PLUS_SOS_EOS = 50\n",
    "\n",
    "# We only keep sentences that do not exceed 48 words, so that later when we\n",
    "# add <s> and </s> to a sentence it still won't exceed 50 words.\n",
    "def filter_data(src_sentences_list, trg_sentences_list, max_len):\n",
    "  new_src_sentences_list, new_trg_sentences_list = [], []\n",
    "  for src_sent, trg_sent in zip(src_sentences_list, trg_sentences_list):\n",
    "    if (len(src_sent) <= max_len and len(trg_sent) <= max_len\n",
    "        and len(src_sent) > 0 and len(trg_sent)) > 0:\n",
    "      new_src_sentences_list.append(src_sent)\n",
    "      new_trg_sentences_list.append(trg_sent)\n",
    "  return new_src_sentences_list, new_trg_sentences_list\n",
    "\n",
    "train_src_sentences_list, train_trg_sentences_list = filter_data(\n",
    "    train_src_sentences_list, train_trg_sentences_list, max_len=MAX_SENT_LENGTH)\n",
    "test_src_sentences_list, test_trg_sentences_list = filter_data(\n",
    "    test_src_sentences_list, test_trg_sentences_list, max_len=MAX_SENT_LENGTH)\n",
    "\n",
    "# We take 10% of training data as validation set.\n",
    "num_val = int(len(train_src_sentences_list) * 0.1)\n",
    "val_src_sentences_list = train_src_sentences_list[:num_val]\n",
    "val_trg_sentences_list = train_trg_sentences_list[:num_val]\n",
    "train_src_sentences_list = train_src_sentences_list[num_val:]\n",
    "train_trg_sentences_list = train_trg_sentences_list[num_val:]\n",
    "\n",
    "# Show some data stats\n",
    "print(\"Number of training (src, trg) sentence pairs: %d\" %\n",
    "      len(train_src_sentences_list))\n",
    "print(\"Number of validation (src, trg) sentence pairs: %d\" %\n",
    "      len(val_src_sentences_list))\n",
    "print(\"Number of testing (src, trg) sentence pairs: %d\" %\n",
    "      len(test_src_sentences_list))\n",
    "src_vocab_set = ['<pad>'] + src_vocab_set\n",
    "trg_vocab_set = ['<pad>'] + trg_vocab_set\n",
    "print(\"Size of en vocab set (including '<pad>', '<unk>', '<s>', '</s>'): %d\" %\n",
    "      len(src_vocab_set))\n",
    "print(\"Size of vi vocab set (including '<pad>', '<unk>', '<s>', '</s>'): %d\" %\n",
    "      len(trg_vocab_set))\n",
    "\n",
    "length = [len(sent) for sent in train_src_sentences_list]\n",
    "print('Training sentence avg. length: %d ' % np.mean(length))\n",
    "print('Training sentence length at 95-percentile: %d' %\n",
    "      np.percentile(length, 95))\n",
    "print('Training sentence length distribution '\n",
    "      '(x-axis is length range and y-axis is count):\\n')\n",
    "plt.hist(length, bins=5)\n",
    "plt.show()\n",
    "\n",
    "print('Example Vietnamese input: ' + str(train_src_sentences_list[0]))\n",
    "print('Its target English output: ' + str(train_trg_sentences_list[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2x0lhVm_Yxx"
   },
   "source": [
    "Here we define a class called `MTDataset`. It is built on top of the efficient data loader API provided in PyTorch. See Section 5 for explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "muwDBzXM5ijT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "assert device == \"cuda\"   # use gpu whenever you can!\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "# These IDs are reserved.\n",
    "PAD_INDEX = 0\n",
    "UNK_INDEX = 1\n",
    "SOS_INDEX = 2\n",
    "EOS_INDEX = 3\n",
    "\n",
    "\n",
    "class MTDataset(data.Dataset):\n",
    "  def __init__(self, src_sentences, src_vocabs, trg_sentences, trg_vocabs,\n",
    "               sampling=1.):\n",
    "    self.src_sentences = src_sentences[:int(len(src_sentences) * sampling)]\n",
    "    self.trg_sentences = trg_sentences[:int(len(src_sentences) * sampling)]\n",
    "\n",
    "    self.max_src_seq_length = MAX_SENT_LENGTH_PLUS_SOS_EOS\n",
    "    self.max_trg_seq_length = MAX_SENT_LENGTH_PLUS_SOS_EOS\n",
    "\n",
    "    self.src_vocabs = src_vocabs\n",
    "    self.trg_vocabs = trg_vocabs\n",
    "\n",
    "    self.src_v2id = {v : i for i, v in enumerate(src_vocabs)}\n",
    "    self.src_id2v = {val : key for key, val in self.src_v2id.items()}\n",
    "    self.trg_v2id = {v : i for i, v in enumerate(trg_vocabs)}\n",
    "    self.trg_id2v = {val : key for key, val in self.trg_v2id.items()}\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.src_sentences)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    src_sent = self.src_sentences[index]\n",
    "    src_len = len(src_sent) + 2   # add <s> and </s> to each sentence\n",
    "    src_id = []\n",
    "    for w in src_sent:\n",
    "      if w not in self.src_vocabs:\n",
    "        w = '<unk>'\n",
    "      src_id.append(self.src_v2id[w])\n",
    "    src_id = ([SOS_INDEX] + src_id + [EOS_INDEX] + [PAD_INDEX] *\n",
    "              (self.max_src_seq_length - src_len))\n",
    "\n",
    "    trg_sent = self.trg_sentences[index]\n",
    "    trg_len = len(trg_sent) + 2\n",
    "    trg_id = []\n",
    "    for w in trg_sent:\n",
    "      if w not in self.trg_vocabs:\n",
    "        w = '<unk>'\n",
    "      trg_id.append(self.trg_v2id[w])\n",
    "    trg_id = ([SOS_INDEX] + trg_id + [EOS_INDEX] + [PAD_INDEX] *\n",
    "              (self.max_trg_seq_length - trg_len))\n",
    "\n",
    "    return torch.tensor(src_id), src_len, torch.tensor(trg_id), trg_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kb5gQEp7oVdi"
   },
   "source": [
    "## **Section 2: Encoder**\n",
    "\n",
    "Seq2seq consists of an Encoder RNN and a decoder RNN. In a vanilla seq2seq model where there is no attention mechanism between encoder and decoder, the encoder aims to compress the information contained in the entire input sequence into a single vector and pass it to decoder.\n",
    "\n",
    "We start with implementing the encoder, which is just a simple RNN. We use a GRU here, but feel free to try other cell types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnwVGDVkoPt0"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, dropout=0.):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "      - `input_size`: an int representing the RNN input size.\n",
    "      - `hidden_size`: an int representing the RNN hidden size.\n",
    "      - `dropout`: a float representing the dropout rate during training. Note\n",
    "          that for 1-layer RNN this has no effect since dropout only applies to\n",
    "          outputs of intermediate layers.\n",
    "    \"\"\"\n",
    "    super(Encoder, self).__init__()\n",
    "    \n",
    "    # Note: for lab writeup question #4, you can directly change `num_layers`\n",
    "    # and `bidirectional` here to enable deep/bidirectional RNNs. However, you\n",
    "    # will also need to modify some parts in the rest of the code accordingly.\n",
    "    self.rnn = nn.GRU(input_size, hidden_size, num_layers=1, batch_first=True,\n",
    "                      dropout=dropout, bidirectional=False)\n",
    "\n",
    "  def forward(self, inputs, lengths):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      - `inputs`: a 3d-tensor of shape (batch_size, max_seq_length, embed_size)\n",
    "          representing a batch of padded embedded word vectors of source\n",
    "          sentences.\n",
    "      - `lengths`: a 1d-tensor of shape (batch_size,) representing the sequence\n",
    "          lengths of `inputs`.\n",
    "\n",
    "    Returns:\n",
    "      - `outputs`: a 3d-tensor of shape\n",
    "        (batch_size, max_seq_length, hidden_size).\n",
    "      - `finals`: a 3d-tensor of shape (num_layers, batch_size, hidden_size).\n",
    "      Hint: `outputs` and `finals` are both standard GRU outputs. Check:\n",
    "      https://pytorch.org/docs/stable/nn.html#gru\n",
    "    \"\"\"\n",
    "    packed_inputs = pack_padded_sequence(inputs,lengths,batch_first=True,enforce_sorted=False)\n",
    "    outputs, finals = self.rnn(packed_inputs) #output(128,50,256), finals(1,128,256)\n",
    "    outputs, _ = pad_packed_sequence(outputs, batch_first=True, total_length=MAX_SENT_LENGTH_PLUS_SOS_EOS)\n",
    "\n",
    "    return outputs, finals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Oz3Kc4QKyEP"
   },
   "source": [
    "## **Section 3: Decoder**\n",
    "\n",
    "Here you will implement a decoder RNN that uses encoder's last hidden state to initialize its initial hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JYT0BlfYUJXj"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  \"\"\"An RNN decoder without attention.\"\"\"\n",
    "\n",
    "  def __init__(self, input_size, hidden_size, dropout=0.):\n",
    "    \"\"\"\n",
    "      Inputs:\n",
    "        - `input_size`, `hidden_size`, and `dropout` the same as in Encoder.\n",
    "    \"\"\"\n",
    "    super(Decoder, self).__init__()\n",
    "    self.dropout=nn.Dropout(p=dropout)\n",
    "    self.pre_output=nn.Linear(hidden_size+input_size,hidden_size,bias=False)\n",
    "    self.f_hidden = nn.Linear(hidden_size, hidden_size)\n",
    "    self.rnn = nn.GRU(input_size, hidden_size, num_layers=1, batch_first=True,\n",
    "                      dropout=dropout, bidirectional=False)\n",
    "    \n",
    "  def forward(self, inputs, encoder_finals, hidden=None, max_len=None):\n",
    "    \"\"\"Unroll the decoder one step at a time.\n",
    "\n",
    "    Inputs:\n",
    "      - `inputs`: a 3d-tensor of shape (batch_size, max_seq_length, embed_size)\n",
    "          representing a batch of padded embedded word vectors of target\n",
    "          sentences (for teacher-forcing during training).\n",
    "      - `encoder_finals`: a 3d-tensor of shape\n",
    "          (num_enc_layers, batch_size, hidden_size) representing the final\n",
    "          encoder hidden states used to initialize the initial decoder hidden\n",
    "          states.\n",
    "      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size) representing\n",
    "          the value to be used to initialize the initial decoder hidden states.\n",
    "          If None, then use `encoder_finals`.\n",
    "      - `max_len`: an int representing the maximum decoding length.\n",
    "\n",
    "    Returns:\n",
    "      - `outputs`: a 3d-tensor of shape\n",
    "          (batch_size, max_seq_length, hidden_size) representing the raw\n",
    "          decoder outputs (before converting to a `trg_vocab_size`-dim vector).\n",
    "          We will convert it later in a `Generator` below.\n",
    "      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size)\n",
    "          representing the last decoder hidden state.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The maximum number of steps to unroll the RNN.\n",
    "    if max_len is None:\n",
    "      max_len = inputs.size(1)\n",
    "\n",
    "    # Initialize decoder hidden state.\n",
    "    if hidden is None:\n",
    "      hidden = self.init_hidden(encoder_finals)#encoder_finals)\n",
    "\n",
    "    pre_outputs = []\n",
    "    for i in range(max_len):\n",
    "      prev_embed=inputs[:,i].unsqueeze(1)\n",
    "      context=hidden[-1].unsqueeze(0)\n",
    "      output, hidden = self.rnn(prev_embed,hidden)\n",
    "\n",
    "      pre_output=torch.cat([prev_embed, output], dim=2)\n",
    "      pre_output=self.dropout(pre_output)\n",
    "      pre_output=self.pre_output(pre_output)\n",
    "      pre_outputs.append(pre_output)\n",
    "\n",
    "    outputs=torch.cat(pre_outputs, dim=1)\n",
    "\n",
    "    return hidden, outputs\n",
    "\n",
    "  def init_hidden(self, encoder_finals):\n",
    "    \"\"\"Use encoder final hidden state to initialize decoder's first hidden\n",
    "    state.\"\"\"\n",
    "    ### Your code here!\n",
    "    return torch.tanh(self.f_hidden(encoder_finals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AH0VdHE2_x1k"
   },
   "source": [
    "Define the high level encoder-decoder class to wrap up sub-models, including encoder, decoder, generator, and src/trg embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nNBaAYB_oHxG"
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "  \"\"\"A standard Encoder-Decoder architecture without attention.\n",
    "  \"\"\"\n",
    "  def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      - `encoder`: an `Encoder` object.\n",
    "      - `decoder`: an `Decoder` object.\n",
    "      - `src_embed`: an nn.Embedding object representing the lookup table for\n",
    "          input (source) sentences.\n",
    "      - `trg_embed`: an nn.Embedding object representing the lookup table for\n",
    "          output (target) sentences.\n",
    "      - `generator`: a `Generator` object. Essentially a linear mapping. See\n",
    "          the next code cell.\n",
    "    \"\"\"\n",
    "    super(EncoderDecoder, self).__init__()\n",
    "\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "    self.src_embed = src_embed\n",
    "    self.trg_embed = trg_embed\n",
    "    self.generator = generator\n",
    "\n",
    "  def forward(self, src_ids, trg_ids, src_lengths):\n",
    "    \"\"\"Take in and process masked source and target sequences.\n",
    "\n",
    "    Inputs:\n",
    "      `src_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n",
    "        a batch of source sentences of word ids.\n",
    "      `trg_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n",
    "        a batch of target sentences of word ids.\n",
    "      `src_lengths`: a 1d-tensor of shape (batch_size,) representing the\n",
    "        sequence length of `src_ids`.\n",
    "\n",
    "    Returns the decoder outputs, see the above cell.\n",
    "    \"\"\"\n",
    "    encoder_hiddens, encoder_finals = self.encode(src_ids, src_lengths)\n",
    "    del encoder_hiddens   # unused\n",
    "    return self.decode(encoder_finals, trg_ids[:, :-1])\n",
    "\n",
    "  def encode(self, src_ids, src_lengths):\n",
    "    return self.encoder(self.src_embed(src_ids), src_lengths)\n",
    "    \n",
    "  def decode(self, encoder_finals, trg_ids, decoder_hidden=None):\n",
    "    return self.decoder(self.trg_embed(trg_ids), encoder_finals, decoder_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M06QOTbCALGy"
   },
   "source": [
    "It simply projects the pre-output layer (x in the forward function below) to obtain the output layer, so that the final dimension is the target vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LaHdVcF1KPmd"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "  \"\"\"Define standard linear + softmax generation step.\"\"\"\n",
    "  def __init__(self, hidden_size, vocab_size):\n",
    "    super(Generator, self).__init__()\n",
    "    self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qf8Oc9a_ocC_"
   },
   "source": [
    "## **Section 4: Attention-Based Decoder**\n",
    "\n",
    "Now it's time to add some attention to the decoder. You can implement any attention mechanism you want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iZq2NImAoY1C"
   },
   "outputs": [],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "  \"\"\"Bahdanau Attention. An attention-based RNN decoder.\"\"\"\n",
    "\n",
    "  def __init__(self, input_size, hidden_size, dropout=0.):\n",
    "    \"\"\"\n",
    "      Inputs:\n",
    "        - `input_size`, `hidden_size`, and `dropout` the same as in Encoder.\n",
    "    \"\"\"\n",
    "    super(AttentionDecoder, self).__init__()\n",
    "    \n",
    "    self.rnn = nn.GRU(input_size + hidden_size, hidden_size, batch_first=True,\n",
    "                      dropout=dropout)\n",
    "    ##attention\n",
    "    self.alphas=None\n",
    "    self.query=nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "    self.energy=nn.Linear(hidden_size, 1, bias=False)\n",
    "    self.key=nn.Linear(hidden_size,hidden_size, bias=False)\n",
    "\n",
    "    self.dropout=nn.Dropout(p=dropout)\n",
    "    self.pre_output=nn.Linear(hidden_size+hidden_size+input_size,hidden_size,bias=False)\n",
    "    self.f_hidden = nn.Linear(hidden_size, hidden_size)\n",
    "    \n",
    "\n",
    "  def forward(self, inputs, encoder_hiddens, encoder_finals,\n",
    "              src_mask, trg_mask, hidden=None, max_len=None):\n",
    "    # The maximum number of steps to unroll the RNN.\n",
    "    if max_len is None:\n",
    "      max_len = trg_mask.size(-1)\n",
    "\n",
    "    # Initialize decoder hidden state.\n",
    "    if hidden is None:\n",
    "      hidden = self.init_hidden(encoder_finals)\n",
    "\n",
    "    proj_key=self.key(encoder_hiddens)\n",
    "    pre_outputs = []\n",
    "    decoder_states = []\n",
    "\n",
    "    #for loop step forward\n",
    "    for i in range(max_len):\n",
    "      prev_embed=inputs[:,i].unsqueeze(1)\n",
    "      #Attention function\n",
    "      query=hidden[-1].unsqueeze(1)\n",
    "      context, attn_probs = self.attention(query, proj_key, encoder_hiddens, src_mask)\n",
    "      \n",
    "      rnn_input=torch.cat([prev_embed,context],dim=2)\n",
    "      output, hidden = self.rnn(rnn_input,hidden)\n",
    "\n",
    "      pre_output=torch.cat([prev_embed, output, context], dim=2)\n",
    "      pre_output=self.dropout(pre_output)\n",
    "      pre_output=self.pre_output(pre_output)\n",
    "      pre_outputs.append(pre_output)\n",
    "\n",
    "    pre_outputs=torch.cat(pre_outputs, dim=1)\n",
    "    return hidden, pre_outputs\n",
    "\n",
    "  def init_hidden(self, encoder_finals):\n",
    "    \"\"\"Use encoder final hidden state to initialize decoder's first hidden\n",
    "    state.\"\"\"\n",
    "    return torch.tanh(self.f_hidden(encoder_finals))\n",
    "\n",
    "  def attention(self, query, proj_key, encoder_hiddens, mask):\n",
    "    query=self.query(query)\n",
    "\n",
    "    scores=self.energy(torch.tanh(query+proj_key))\n",
    "    scores=scores.squeeze(2).unsqueeze(1)\n",
    "    scores.data.masked_fill_(mask == 0, -float('inf'))\n",
    "    \n",
    "    alphas=F.softmax(scores,dim=-1)\n",
    "    self.alphas=alphas\n",
    "    \n",
    "    context=torch.bmm(alphas, encoder_hiddens)\n",
    "\n",
    "    return context, alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DTUXxJWPPQ9W"
   },
   "source": [
    "Similarly, we use a `EncoderAttentionDecoder` class to wrap up all encoder, decoder, src/trg embeddings, and generator. You can take the `EncoderDecoder` class as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mghIa6XzubZL"
   },
   "outputs": [],
   "source": [
    "class EncoderAttentionDecoder(nn.Module):\n",
    "  \"\"\"A Encoder-Decoder architecture with attention.\n",
    "  \"\"\"\n",
    "  def __init__(self, encoder, decoder, src_embed , trg_embed, generator):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      - `encoder`: an `Encoder` object.\n",
    "      - `decoder`: an `AttentionDecoder` object.\n",
    "      - `src_embed`: an nn.Embedding object representing the lookup table for\n",
    "          input (source) sentences.\n",
    "      - `trg_embed`: an nn.Embedding object representing the lookup table for\n",
    "          output (target) sentences.\n",
    "      - `generator`: a `Generator` object. Essentially a linear mapping. See\n",
    "          the next code cell.\n",
    "    \"\"\"\n",
    "    super(EncoderAttentionDecoder, self).__init__()\n",
    "\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "    self.src_embed = src_embed\n",
    "    self.trg_embed = trg_embed\n",
    "    self.generator = generator\n",
    "\n",
    "  def forward(self, src_ids, trg_ids, src_lengths):\n",
    "    \"\"\"Take in and process masked source and target sequences.\n",
    "\n",
    "    Inputs:\n",
    "      `src_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n",
    "        a batch of source sentences of word ids.\n",
    "      `trg_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n",
    "        a batch of target sentences of word ids.\n",
    "      `src_lengths`: a 1d-tensor of shape (batch_size,) representing the\n",
    "        sequence length of `src_ids`.\n",
    "\n",
    "    Returns the decoder outputs, see the above cell.\n",
    "    \"\"\"\n",
    "    ### Your code here!\n",
    "    # You can refer to `EncoderDecoder` and extend from it.\n",
    "    encoder_hiddens, encoder_finals = self.encode(src_ids, src_lengths)\n",
    "    src_mask = (src_ids != PAD_INDEX).unsqueeze(-2)\n",
    "    trg_mask = (trg_ids[:, 1:] != PAD_INDEX).unsqueeze(-2)\n",
    "    return self.decode(encoder_hiddens, encoder_finals,\n",
    "                       src_mask, trg_ids[:, :-1], trg_mask)\n",
    "\n",
    "  def encode(self, src_ids, src_lengths):\n",
    "    return self.encoder(self.src_embed(src_ids), src_lengths)\n",
    "\n",
    "  def decode(self, encoder_hiddens, encoder_finals, src_mask, \n",
    "             trg_ids, trg_mask, hidden=None):\n",
    "    return self.decoder(self.trg_embed(trg_ids), encoder_hiddens,\n",
    "                        encoder_finals, src_mask, trg_mask, hidden)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9VIpNlKtK8l_"
   },
   "source": [
    "## **Section 5: Training and Testing**\n",
    "\n",
    "We provide training and testing scripts here. You might need to adapt them to fit your model implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I38IFq48BKa5"
   },
   "source": [
    "Apply the dataloader to the MT dataset. Dataloader provides a convenient way to iterate through the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJrXO7nCjzBP"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# You can try on a smaller training set by setting a smaller `sampling`.\n",
    "train_set = MTDataset(train_src_sentences_list, src_vocab_set,\n",
    "                      train_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
    "train_data_loader = data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                    num_workers=8, shuffle=True)\n",
    "\n",
    "val_set = MTDataset(val_src_sentences_list, src_vocab_set,\n",
    "                    val_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
    "val_data_loader = data.DataLoader(val_set, batch_size=batch_size, num_workers=8,\n",
    "                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bWaiu7wNBX7x"
   },
   "source": [
    "The main functions for training, here we use perplexity to evaluate the performance of the model. Although we provide the training scripts here, we strongly encoureage you to go through and understand the procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AXGa-L1qp13q"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class SimpleLossCompute:\n",
    "  \"\"\"A simple loss compute and train function.\"\"\"\n",
    "\n",
    "  def __init__(self, generator, criterion, opt=None):\n",
    "    self.generator = generator\n",
    "    self.criterion = criterion\n",
    "    self.opt = opt\n",
    "\n",
    "  def __call__(self, x, y, norm):\n",
    "    x = self.generator(x)\n",
    "    loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n",
    "                          y.contiguous().view(-1))\n",
    "    loss = loss / norm\n",
    "\n",
    "    if self.opt is not None:  # training mode\n",
    "      loss.backward()          \n",
    "      self.opt.step()\n",
    "      self.opt.zero_grad()\n",
    "\n",
    "    return loss.data.item() * norm\n",
    "\n",
    "\n",
    "def run_epoch(data_loader, model, loss_compute, print_every):\n",
    "  \"\"\"Standard Training and Logging Function\"\"\"\n",
    "\n",
    "  total_tokens = 0\n",
    "  total_loss = 0\n",
    "\n",
    "  for i, (src_ids_BxT, src_lengths_B, trg_ids_BxL, trg_lengths_B) in enumerate(data_loader):\n",
    "    # We define some notations here to help you understand the loaded tensor\n",
    "    # shapes:\n",
    "    #   `B`: batch size\n",
    "    #   `T`: max sequence length of source sentences\n",
    "    #   `L`: max sequence length of target sentences; due to our preprocessing\n",
    "    #        in the beginning, `L` == `T` == 50\n",
    "    # An example of `src_ids_BxT` (when B = 2):\n",
    "    #   [[2, 4, 6, 7, ..., 4, 3, 0, 0, 0],\n",
    "    #    [2, 8, 6, 5, ..., 9, 5, 4, 3, 0]]\n",
    "    # The corresponding `src_lengths_B` would be [47, 49].\n",
    "    # Note that SOS_INDEX == 2, EOS_INDEX == 3, and PAD_INDEX = 0.\n",
    "\n",
    "    src_ids_BxT = src_ids_BxT.to(device)\n",
    "    src_lengths_B = src_lengths_B.to(device)\n",
    "    trg_ids_BxL = trg_ids_BxL.to(device)\n",
    "    del trg_lengths_B   # unused\n",
    "\n",
    "    _, output = model(src_ids_BxT, trg_ids_BxL, src_lengths_B)\n",
    "\n",
    "    loss = loss_compute(x=output, y=trg_ids_BxL[:, 1:],\n",
    "                        norm=src_ids_BxT.size(0))\n",
    "    total_loss += loss\n",
    "    total_tokens += (trg_ids_BxL[:, 1:] != PAD_INDEX).data.sum().item()\n",
    "\n",
    "    if model.training and i % print_every == 0:\n",
    "      print(\"Epoch Step: %d Loss: %f\" % (i, loss / src_ids_BxT.size(0)))\n",
    "\n",
    "  return math.exp(total_loss / float(total_tokens))\n",
    "\n",
    "\n",
    "def train(model, num_epochs, learning_rate, print_every):\n",
    "  # Set `ignore_index` as PAD_INDEX so that pad tokens won't be included when\n",
    "  # computing the loss.\n",
    "  criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
    "  optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  # Keep track of dev ppl for each epoch.\n",
    "  dev_ppls = []\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    print(\"Epoch\", epoch)\n",
    "\n",
    "    model.train()\n",
    "    train_ppl = run_epoch(data_loader=train_data_loader, model=model,\n",
    "                          loss_compute=SimpleLossCompute(model.generator,\n",
    "                                                         criterion, optim),\n",
    "                          print_every=print_every)\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():      \n",
    "      dev_ppl = run_epoch(data_loader=val_data_loader, model=model,\n",
    "                          loss_compute=SimpleLossCompute(model.generator,\n",
    "                                                         criterion, None),\n",
    "                          print_every=print_every)\n",
    "      print(\"Validation perplexity: %f\" % dev_ppl)\n",
    "      dev_ppls.append(dev_ppl)\n",
    "        \n",
    "  return dev_ppls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1A8VvkcICT60"
   },
   "source": [
    "The main function to perform training. First let's train the vanilla seq2seq model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9860,
     "status": "ok",
     "timestamp": 1587835732356,
     "user": {
      "displayName": "ByeongJo Kong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64",
      "userId": "10931837966081205326"
     },
     "user_tz": 240
    },
    "id": "pZ0t1hXAIHtO",
    "outputId": "71ecebcd-16ea-4344-92f0-1694e98f2e8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for contructing the encoder-decoder model.\n",
    "\n",
    "embed_size = 256   # Each word will be represented as a `embed_size`-dim vector.\n",
    "hidden_size = 256  # RNN hidden size.\n",
    "dropout = 0.2\n",
    "\n",
    "pure_seq2seq = EncoderDecoder(\n",
    "  encoder=Encoder(embed_size, hidden_size, dropout=dropout),\n",
    "  decoder=Decoder(embed_size, hidden_size, dropout=dropout),\n",
    "  src_embed=nn.Embedding(len(src_vocab_set), embed_size),\n",
    "  trg_embed=nn.Embedding(len(trg_vocab_set), embed_size),\n",
    "  generator=Generator(hidden_size, len(trg_vocab_set))).to(device)\n",
    "\n",
    "# Start training. The returned `dev_ppls` is a list of dev perplexity for each\n",
    "# epoch.\n",
    "#pure_dev_ppls = train(pure_seq2seq, num_epochs=10, learning_rate=1e-3,\n",
    "#                      print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fRsfDg0wCa7U"
   },
   "source": [
    "Plot the perplexity graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1254,
     "status": "ok",
     "timestamp": 1587796752300,
     "user": {
      "displayName": "ByeongJo Kong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64",
      "userId": "10931837966081205326"
     },
     "user_tz": 240
    },
    "id": "CTApnlT53YvT",
    "outputId": "bbdb88bb-4b4f-46de-9ea2-a6afa3335fe9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_perplexity(perplexities):\n",
    "  \"\"\"plot perplexities\"\"\"\n",
    "  plt.title(\"Perplexity per Epoch\")\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Perplexity\")\n",
    "  plt.plot(perplexities)\n",
    "\n",
    "plot_perplexity(pure_dev_ppls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PjhKXDyvIk4l"
   },
   "source": [
    "Now, let's train the seq2seq model with attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1587835735574,
     "user": {
      "displayName": "ByeongJo Kong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64",
      "userId": "10931837966081205326"
     },
     "user_tz": 240
    },
    "id": "onQxDU-aGa0t",
    "outputId": "aa8541a0-5a42-4cce-e2c8-12c1e687e85c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "attn_seq2seq = EncoderAttentionDecoder(\n",
    "    encoder=Encoder(embed_size, hidden_size, dropout=dropout),\n",
    "    decoder=AttentionDecoder(embed_size, hidden_size, dropout=dropout),\n",
    "    src_embed=nn.Embedding(len(src_vocab_set), embed_size),\n",
    "    trg_embed=nn.Embedding(len(trg_vocab_set), embed_size),\n",
    "    generator=Generator(hidden_size, len(trg_vocab_set))).to(device)\n",
    "\n",
    "#attn_dev_ppls = train(attn_seq2seq, num_epochs=10, learning_rate=1e-3,\n",
    "#                      print_every=100)\n",
    "\n",
    "#plot_perplexity(attn_dev_ppls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMpL-_MwJOws"
   },
   "source": [
    "This is the function used to decode the model output. For simplicity, we use greedy search here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M1HTqYwy6-yL"
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, src_ids, src_lengths, max_len):\n",
    "  \"\"\"Greedily decode a sentence for EncoderDecoder.\"\"\"\n",
    "\n",
    "  with torch.no_grad():\n",
    "    _, encoder_finals = model.encode(src_ids, src_lengths)\n",
    "    prev_y = torch.ones(1, 1).fill_(SOS_INDEX).type_as(src_ids)\n",
    "\n",
    "  output = []\n",
    "  hidden = None\n",
    "\n",
    "  for i in range(max_len):\n",
    "    with torch.no_grad():\n",
    "      hidden, outputs = model.decode(encoder_finals, prev_y, hidden)\n",
    "      prob = model.generator(outputs[:, -1])\n",
    "\n",
    "    _, next_word = torch.max(prob, dim=1)\n",
    "    next_word = next_word.data.item()\n",
    "    output.append(next_word)\n",
    "    prev_y = torch.ones(1, 1).type_as(src_ids).fill_(next_word)\n",
    "\n",
    "  output = np.array(output)\n",
    "\n",
    "  # Cut off everything starting from </s>.\n",
    "  first_eos = np.where(output == EOS_INDEX)[0]\n",
    "  if len(first_eos) > 0:\n",
    "    output = output[:first_eos[0]]\n",
    "  return output\n",
    "\n",
    "\n",
    "def greedy_decode_attention(model, src_ids, src_lengths, max_len):\n",
    "  \"\"\"Greedily decode a sentence for EncoderAttentionDecoder.\"\"\"\n",
    "\n",
    "  with torch.no_grad():\n",
    "    src_mask = (src_ids != PAD_INDEX).unsqueeze(-2)\n",
    "    encoder_hiddens, encoder_finals = model.encode(src_ids, src_lengths)\n",
    "    prev_y = torch.ones(1, 1).fill_(SOS_INDEX).type_as(src_ids)\n",
    "    trg_mask = torch.ones_like(prev_y)\n",
    "\n",
    "  output = []\n",
    "  attention_scores = []\n",
    "  hidden = None\n",
    "\n",
    "  for i in range(max_len):\n",
    "    with torch.no_grad():\n",
    "      hidden, outputs = model.decode(encoder_hiddens, encoder_finals, src_mask,\n",
    "                                     prev_y, trg_mask, hidden)\n",
    "      prob = model.generator(outputs[:, -1])\n",
    "\n",
    "    _, next_word = torch.max(prob, dim=1)\n",
    "    next_word = next_word.data.item()\n",
    "    output.append(next_word)\n",
    "    prev_y = torch.ones(1, 1).fill_(next_word).type_as(src_ids)\n",
    "    attention_scores.append(model.decoder.alphas.cpu().numpy())\n",
    "\n",
    "  output = np.array(output)\n",
    "\n",
    "  # Cut off everything starting from </s>.\n",
    "  first_eos = np.where(output == EOS_INDEX)[0]\n",
    "  if len(first_eos) > 0:\n",
    "    output = output[:first_eos[0]]\n",
    "\n",
    "  return output, np.concatenate(attention_scores, axis=1)\n",
    "  \n",
    "def lookup_words(x, vocab):\n",
    "  return [vocab[i] for i in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_5go3VxJZKh"
   },
   "source": [
    "Print the top 3 examples from the data loader by applying the greedy decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cc3m4optFrb3"
   },
   "outputs": [],
   "source": [
    "def print_examples(model, data_loader, n=3,\n",
    "                   max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS, \n",
    "                   src_vocab_set=src_vocab_set, trg_vocab_set=trg_vocab_set):\n",
    "  \"\"\"Prints `n` examples. Assumes batch size of 1.\"\"\"\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  for i, (src_ids, src_lengths, trg_ids, _) in enumerate(data_loader):\n",
    "    if isinstance(model, EncoderDecoder):\n",
    "      result = greedy_decode(model, src_ids.to(device), src_lengths.to(device),\n",
    "                             max_len=max_len)\n",
    "    elif isinstance(model, EncoderAttentionDecoder):\n",
    "      result, _ = greedy_decode_attention(model, src_ids.to(device),\n",
    "                                          src_lengths.to(device),\n",
    "                                          max_len=max_len)\n",
    "    else:\n",
    "      raise NotImplementedError(\"Unknown model type.\")\n",
    "\n",
    "    # remove <s>\n",
    "    src_ids = src_ids[0, 1:]\n",
    "    trg_ids = trg_ids[0, 1:]\n",
    "    # remove </s> and <pad>\n",
    "    src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n",
    "    trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n",
    "\n",
    "    print(\"Example #%d\" % (i + 1))\n",
    "    print(\"Src : \", \" \".join(lookup_words(src_ids, vocab=src_vocab_set)))\n",
    "    print(\"Trg : \", \" \".join(lookup_words(trg_ids, vocab=trg_vocab_set)))\n",
    "    print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab_set)))\n",
    "    print()\n",
    "\n",
    "    if i == n - 1:\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l7Hi4X0GJouK"
   },
   "source": [
    "Here we use the validation dataset to print examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1695,
     "status": "ok",
     "timestamp": 1587798596273,
     "user": {
      "displayName": "ByeongJo Kong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64",
      "userId": "10931837966081205326"
     },
     "user_tz": 240
    },
    "id": "27thJIfreCgB",
    "outputId": "e3e02ed4-8dc4-4eb5-c53f-a8d96d1f5535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example #1\n",
      "Src :  Khoa học đằng sau một tiêu đề về khí hậu\n",
      "Trg :  Rachel <unk> : The science behind a climate headline\n",
      "Pred:  Science : The problem of the climate crisis .\n",
      "\n",
      "Example #2\n",
      "Src :  Tôi muốn cho các bạn biết về sự to lớn của những nỗ lực khoa học đã góp phần làm nên các dòng tít bạn thường thấy trên báo .\n",
      "Trg :  I &apos;d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .\n",
      "Pred:  I want to tell you about the public health of the <unk> that &apos;s going to be so much more difficult to see .\n",
      "\n",
      "Example #3\n",
      "Src :  Có những dòng trông như thế này khi bàn về biến đổi khí hậu , và như thế này khi nói về chất lượng không khí hay khói bụi .\n",
      "Trg :  <unk> that look like this when they have to do with climate change , and headlines that look like this when they have to do with air quality or smog .\n",
      "Pred:  There are the things that look like this , and if it &apos;s like the air , it &apos;s like the <unk> <unk> .\n",
      "\n",
      "Example #1\n",
      "Src :  Khoa học đằng sau một tiêu đề về khí hậu\n",
      "Trg :  Rachel <unk> : The science behind a climate headline\n",
      "Pred:  Science is a climate change on the climate .\n",
      "\n",
      "Example #2\n",
      "Src :  Tôi muốn cho các bạn biết về sự to lớn của những nỗ lực khoa học đã góp phần làm nên các dòng tít bạn thường thấy trên báo .\n",
      "Trg :  I &apos;d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .\n",
      "Pred:  I want to tell you about the big <unk> of science that takes the way to make you all the time .\n",
      "\n",
      "Example #3\n",
      "Src :  Có những dòng trông như thế này khi bàn về biến đổi khí hậu , và như thế này khi nói về chất lượng không khí hay khói bụi .\n",
      "Trg :  <unk> that look like this when they have to do with climate change , and headlines that look like this when they have to do with air quality or smog .\n",
      "Pred:  There are these lines of these things when they talk about climate change , and like this , when you talk about quality of air or smoke .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_set = MTDataset(val_src_sentences_list, src_vocab_set,\n",
    "                        val_trg_sentences_list, trg_vocab_set)\n",
    "example_data_loader = data.DataLoader(val_set, batch_size=1, num_workers=1,\n",
    "                                      shuffle=False)\n",
    "\n",
    "print_examples(pure_seq2seq, example_data_loader)\n",
    "\n",
    "print_examples(attn_seq2seq, example_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5pTV5PqJtX4"
   },
   "source": [
    "Compute the BLEU score. BLEU score is a standard measure to evaluate the translation results. For further details, you can refer to [this](https://en.wikipedia.org/wiki/BLEU) link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 118734,
     "status": "ok",
     "timestamp": 1587798119996,
     "user": {
      "displayName": "ByeongJo Kong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64",
      "userId": "10931837966081205326"
     },
     "user_tz": 240
    },
    "id": "6XGQYwHRPyne",
    "outputId": "a9f8ad70-09f8-478d-c1e3-a695a9f65210"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1139/1139 [00:50<00:00, 22.77it/s]\n",
      "  0%|          | 0/1139 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 6.825054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1139/1139 [01:07<00:00, 16.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 15.098443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def compute_BLEU(model, data_loader):\n",
    "  bleu_score = []\n",
    "\n",
    "  model.eval()\n",
    "  for src_ids, src_lengths, trg_ids, _ in tqdm(data_loader):\n",
    "    if isinstance(model, EncoderDecoder):\n",
    "      result = greedy_decode(model, src_ids.to(device), src_lengths.to(device),\n",
    "                             max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS)\n",
    "    elif isinstance(model, EncoderAttentionDecoder):\n",
    "      result, _ = greedy_decode_attention(model, src_ids.to(device),\n",
    "                                          src_lengths.to(device),\n",
    "                                          max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS)\n",
    "    # remove <s>\n",
    "    src_ids = src_ids[0, 1:]\n",
    "    trg_ids = trg_ids[0, 1:]\n",
    "    # remove </s> and <pad>\n",
    "    src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n",
    "    trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n",
    "\n",
    "    pred = \" \".join(lookup_words(result, vocab=trg_vocab_set))\n",
    "    targ = \" \".join(lookup_words(trg_ids, vocab=trg_vocab_set))\n",
    "\n",
    "    bleu_score.append(sacrebleu.raw_corpus_bleu([pred], [[targ]], .01).score)\n",
    "\n",
    "  return bleu_score\n",
    "\n",
    "\n",
    "test_set = MTDataset(test_src_sentences_list, src_vocab_set,\n",
    "                     test_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
    "test_data_loader = data.DataLoader(test_set, batch_size=1, num_workers=8,\n",
    "                                   shuffle=False)\n",
    "\n",
    "print('BLEU score: %f' % (np.mean(compute_BLEU(pure_seq2seq,\n",
    "                                               test_data_loader))))\n",
    "print('BLEU score: %f' % (np.mean(compute_BLEU(attn_seq2seq,\n",
    "                                               test_data_loader))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aVxViAwwxo6U"
   },
   "source": [
    "### **Visualizing Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1587835678923,
     "user": {
      "displayName": "ByeongJo Kong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64",
      "userId": "10931837966081205326"
     },
     "user_tz": 240
    },
    "id": "rLyxyIcDMlRE",
    "outputId": "09abc206-8d49-4e2b-9ea9-633918ce7f2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f3a7280fac8>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_loader = data.DataLoader(val_set, batch_size=1, num_workers=1,shuffle=False)\n",
    "map_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 399,
     "status": "ok",
     "timestamp": 1587835937332,
     "user": {
      "displayName": "ByeongJo Kong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64",
      "userId": "10931837966081205326"
     },
     "user_tz": 240
    },
    "id": "0pogoWfvXn_Q",
    "outputId": "89942520-ae48-4c55-c642-ec148a0101d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 17192])\n"
     ]
    }
   ],
   "source": [
    "src_ids, src_lengths, trg_ids, _ = next(iter(map_loader))\n",
    "max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS\n",
    "model=attn_seq2seq\n",
    "#src_ids_origin=src_ids\n",
    "\n",
    "with torch.no_grad():\n",
    "  src_mask = (src_ids != PAD_INDEX).unsqueeze(-2)\n",
    "  encoder_hiddens, encoder_finals = model.encode(src_ids.to(device), src_lengths)\n",
    "  prev_y = torch.ones(1, 1).fill_(SOS_INDEX).type_as(src_ids)\n",
    "  trg_mask = torch.ones_like(prev_y)\n",
    "\n",
    "output = []\n",
    "attention_scores = []\n",
    "hidden = None\n",
    "\n",
    "for i in range(max_len):\n",
    "  with torch.no_grad():\n",
    "    hidden, outputs = model.decode(encoder_hiddens, encoder_finals, src_mask.to(device),\n",
    "                                   prev_y.to(device), trg_mask.to(device), hidden)\n",
    "    prob = model.generator(outputs[:, -1])\n",
    "\n",
    "  _, next_word = torch.max(prob, dim=1)\n",
    "  next_word = next_word.data.item()\n",
    "  output.append(next_word)\n",
    "  prev_y = torch.ones(1, 1).fill_(next_word).type_as(src_ids)\n",
    "  attention_scores.append(model.decoder.alphas.cpu().numpy())\n",
    "\n",
    "output = np.array(output)\n",
    "print(prob.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1206,
     "status": "ok",
     "timestamp": 1587807978136,
     "user": {
      "displayName": "ByeongJo Kong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64",
      "userId": "10931837966081205326"
     },
     "user_tz": 240
    },
    "id": "VJt-4vjurWIU",
    "outputId": "11b92f14-4548-4887-ea3a-17b6b8a54d29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13])\n",
      "tensor([ 4,  1,  5,  6,  7,  8,  9, 10, 11])\n",
      "[6574  122    9   10   28   27   21   10   47]\n",
      "9\n",
      "tensor([[[0.0581, 0.0590, 0.0406, 0.0305, 0.0367, 0.0244, 0.0523, 0.0440,\n",
      "          0.0376, 0.0850, 0.1390, 0.3928, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000]]], device='cuda:0')\n",
      "<bound method AttentionDecoder.attention of AttentionDecoder(\n",
      "  (rnn): GRU(512, 256, batch_first=True, dropout=0.2)\n",
      "  (query): Linear(in_features=256, out_features=256, bias=False)\n",
      "  (energy): Linear(in_features=256, out_features=1, bias=False)\n",
      "  (key): Linear(in_features=256, out_features=256, bias=False)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (pre_output): Linear(in_features=768, out_features=256, bias=False)\n",
      "  (f_hidden): Linear(in_features=256, out_features=256, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "src_ids, src_lengths, trg_ids, _ = next(iter(map_loader))\n",
    "max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS\n",
    "model=attn_seq2seq\n",
    "src_ids_origin=src_ids\n",
    "#print(\"src_ids\",src_ids)\n",
    "#print(\"length\",src_lengths)\n",
    "#print(\"trg_ids\",trg_ids)\n",
    "\n",
    "pred, attn = greedy_decode_attention(model, src_ids.to(device),\n",
    "                                     src_lengths.to(device),\n",
    "                                     max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS)\n",
    "\n",
    "# remove <s>\n",
    "src_ids = src_ids[0, 1:]\n",
    "trg_ids = trg_ids[0, 1:]\n",
    "# remove </s> and <pad>\n",
    "src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n",
    "trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n",
    "\n",
    "print(src_ids)\n",
    "print(trg_ids)\n",
    "print(pred)\n",
    "print(len(attn[0,:len(pred)]))\n",
    "print(attn_seq2seq.decoder.alphas)\n",
    "\n",
    "\n",
    "print(attn)\n",
    "\n",
    "\n",
    "#plot_heatmap(src, pred, pred_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1255,
     "status": "error",
     "timestamp": 1587806704999,
     "user": {
      "displayName": "ByeongJo Kong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64",
      "userId": "10931837966081205326"
     },
     "user_tz": 240
    },
    "id": "VCVdq__OLt8e",
    "outputId": "f09628de-2869-481b-dc86-78f5c6c8593e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_ids tensor([[ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  3,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
      "length tensor([12])\n",
      "trg_ids tensor([[ 2,  4,  1,  5,  6,  7,  8,  9, 10, 11,  3,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
      "Src :  Khoa học đằng sau một tiêu đề về khí hậu\n",
      "Trg :  Rachel <unk> : The science behind a climate headline\n",
      "Pred:  Science is a climate change on the climate .\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-871a69d946ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_vocab_set\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"</s>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrg_vocab_set\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"</s>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrg_vocab_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"xx\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"</s>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;31m#pred_att = alphas[idx][0].T[:, :len(pred)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mpred_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_seq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "  src_mask = (src_ids != PAD_INDEX).unsqueeze(-2)\n",
    "  encoder_hiddens, encoder_finals = attn_seq2seq.encode(src_ids.to(device), src_lengths)\n",
    "  prev_y = torch.ones(1, 1).fill_(SOS_INDEX).type_as(src_ids)\n",
    "  trg_mask = torch.ones_like(prev_y)\n",
    "\n",
    "  output = []\n",
    "  attention_scores = []\n",
    "  hidden = None\n",
    "\n",
    "  for i in range(max_len):\n",
    "    with torch.no_grad():\n",
    "      hidden, outputs = attn_seq2seq.decode(encoder_hiddens, encoder_finals, src_mask.to(device),\n",
    "                                     prev_y.to(device), trg_mask.to(device), hidden)\n",
    "      prob = attn_seq2seq.generator(outputs[:, -1])\n",
    "\n",
    "    _, next_word = torch.max(prob, dim=1)\n",
    "    next_word = next_word.data.item()\n",
    "    output.append(next_word)\n",
    "    prev_y = torch.ones(1, 1).fill_(next_word).type_as(src_ids)\n",
    "    attention_scores.append(attn_seq2seq.decoder.alphas.cpu().numpy())\n",
    "\n",
    "  output = np.array(output)\n",
    "\n",
    "  # Cut off everything starting from </s>.\n",
    "  first_eos = np.where(output == EOS_INDEX)[0]\n",
    "  if len(first_eos) > 0:\n",
    "    output = output[:first_eos[0]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# remove <s>\n",
    "src_ids = src_ids[0, 1:]\n",
    "trg_ids = trg_ids[0, 1:]\n",
    "# remove </s> and <pad>\n",
    "src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n",
    "trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n",
    "\n",
    "print(\"Src : \", \" \".join(lookup_words(src_ids, vocab=src_vocab_set)))\n",
    "print(\"Trg : \", \" \".join(lookup_words(trg_ids, vocab=trg_vocab_set)))\n",
    "print(\"Pred: \", \" \".join(lookup_words(output, vocab=trg_vocab_set)))\n",
    "\n",
    "\n",
    "idx = 5\n",
    "src = lookup_words(src_ids, vocab=src_vocab_set) + [\"</s>\"]\n",
    "trg = lookup_words(trg_ids, vocab=trg_vocab_set) + [\"</s>\"]\n",
    "pred = lookup_words(output, vocab=trg_vocab_set).split + [\"xx\"] + [\"</s>\"]\n",
    "#pred_att = alphas[idx][0].T[:, :len(pred)]\n",
    "pred_att = attn_seq2seq.decoder.alphas.cpu().numpy().T[:len(pred)]\n",
    "#pred_att=np.concatenate(attention_scores, axis=1)\n",
    "print(len(pred))\n",
    "print(len(src))\n",
    "print(len(pred_att))\n",
    "print(\"attention:\",np.concatenate(attention_scores, axis=1))\n",
    "print(\"ref\", trg)\n",
    "print(\"pred\", pred)\n",
    "plot_heatmap(src, pred, pred_att)\n",
    "\n",
    "\"\"\"\n",
    "src_list=lookup_words(src_ids, vocab=src_vocab_set) + [\"</s>\"]\n",
    "output_list=lookup_words(output, vocab=trg_vocab_set) + [\"xx\"]+[\"</s>\"]\n",
    "print(\"src_list:\",src_list)\n",
    "print(\"output:\",output_list)\n",
    "\n",
    "pred_att = attn_seq2seq.decoder.alphas.cpu().numpy().T[:len(output_list)]\n",
    "print(len(pred_att))\n",
    "print(pred_att)\n",
    "#print(\"size\",src_ids,\" \",trg_ids,\" \", output.size())\n",
    "#print(\"attention:\",np.concatenate(attention_scores, axis=1))\n",
    "attn=np.concatenate(attention_scores, axis=1)\n",
    "plot_heatmap(src_list,output_list,pred_att)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1391,
     "status": "ok",
     "timestamp": 1587806794814,
     "user": {
      "displayName": "ByeongJo Kong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64",
      "userId": "10931837966081205326"
     },
     "user_tz": 240
    },
    "id": "4475XOvcLIgg",
    "outputId": "cf8e89c2-0e9e-4b4c-eebd-9b1f0f482bca"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARQAAAEYCAYAAACdsgkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd3gVxfeH33PTSAhJIIRA6L1JF6UpoIKAFDuoINixYEfsDRXsWH58FcWCYAMFEaQJAoKggFTpHUJLgSRAgJT5/TETuOn3hntvAsz7PPfJ7s7sOTNbzs7MbuYjSiksFovFEziKuwAWi+X8wQYUi8XiMWxAsVgsHsMGFIvF4jFsQLFYLB7DBhSLxeIxbEApIYhIsIj8KiJJIjIxj/SXRWS8l8uwU0SuKkr5zjVE5D4RGWWWq4nIURHxK+5ylUREpKmI/OVK3hIfUPK6yEVkkIgsKq4y5YUHbvgbgWggUil1k4eK5UlKevlcRkQCgeeBtwGUUruVUqFKqYwi2OokIns9XcYC/D0jIm/4yh+AUmoNcEREehWWt8QHFE8jIv7FXYZ8qA5sVkqlF3dB8qHI5fP2MS+C/T7ARqVUrDfK42WuAX7zlTOnYzsBuK/QHZRSJfoH7ASuyrFtELDIaf1pYBuQAqwHrsuRdzHwPpAAjACOABc55YkCUoEKZr0nsMrk+wto6pR3GBBrfG0CrgS6AaeANOAosDqfujQE5hu7/wG9zfZXcux/Vx77vgyMd1rvbWwcMTYbOqVVBX4G4kydPzbbawPzzLZ4c5FEFHSs8yufi7aGAWuAk0AdQAF3AHuAw8BgoLXJcySrnE427gQ2mLyzgOpOaQp4ENgC7ADEnONDQDKw1vkc57D7BfC803oNY8/frM8HhpvrJgWYDZTPw05pc91kmuNyFIgBgoBRwD7zGwUEmX06AXuBJ0xZ9wN3ONnsgb6GU9DX2ZNOaWXNPn7AOqCXU1qAOQ8tzHob9LV7BFgNdHLKe4c5rinAduA+p7Ss8g0DDgDfmO2VTV2DCrxfiztgeCig3GROpAPoCxwDKjnlTQeGAP5AsLmgXnfa/0FgplluYU7apebEDTRlCALqo2+GGKcLsXZeN3we9QgAtgLPAoHAFeaE1ndx/9PpQD1Txy7G7lPGdqAp82r0zVUaKAV0MPvVMfsEoYPoQmBUYQEln4Dmiq1V6OAWzJmb9hNTpq7ACWAKUMFcsIeAjmb/PqZODc15ex74K0dAmQOUM/avBlYAEejg0jDrGsijLsuAmwoJKNvMcQ426yPzsdUJ2Jtj26vAUlOvKPSNPdwpf7rJE4AOIMeBsiZ9P3CZUwBp6WS3H/CdWX4K+MEprQ+w1unmTzC2HeY8JQBRJv0a9ANBgI7Gf8sc5XvTnNtgJx/JOD1cz+WAchQdabN+x3EKKHnsswro4xRQdudIvwrY5rS+GLjdLP8v6+Q7pW8yB76OueivAgIKuuHyKNNl6IjvcNr2HfByEQLKC8CPTmkO9NOsE9AW3TLxd+HYXguszHGsXQooLtq602m9Bvqmrey0LQHo67T+E/CoWZ6BU0vN1PE4ppVibF3hlH4FsBn9ZHbkV06TdwvQLY+yOQcU5xbMA5gHTh62OpE7oGwDejitXw3sdMqf6nx+zDXVxizvRnctwvLw9Q0wwCzHoB9IYWZ9EvCUWR6GaVk47TsLGJhPHaYAjziV7xRQKo98scDlBR3bc2UM5VqlVETWD32CTyMit4vIKhE5IiJHgIuA8k5Z9uSw9wcQIiKXikgNoDkw2aRVB57IsmXsVUW3SrYCj6JvrkMi8r2IxLhYhxhgj1Iq02nbLvTTxF1izL4AGJt7jK2qwC6Vx1iHiESbMseKSDIwnuzHyWVctJXzuAMcdFpOzWM91CxXBz5wOgeJ6Ceq8/E6bV8pNQ/4GPg/9LkZIyJh+RT/MFCmwArq4J/FcadyuUK282OWna+ThBznx9n+DeiWxS4RWSAibQFEJKulMRNAKbUP/SC8QUQigO7obifoY3dTjmu4A1DJ2OouIktFJNGk9SD7uYtTSp3Io15l0A/0fDlXAkq+iEh14DPgIfQbiAh0/1KcsinnfZQezf8RuMX8pimlUkzyHnR3KMLpF6KU+s7s+61SqgP6pCl00zCXjzzYB1Q1F0YW1dBR3132Gf8AiIigA0msKX+1fAYq3zDlbKKUCgP6k/04uYMrtgo7JgWxB923dz4PwUop59eXOc/rh0qpVkAjdHdlaD6215h0T5BXHbOdH/R53ueSMaWWKaX6oLtLU9DXKeixpl1KqTin7F+jj/tNwBJ1ZpB5D7qF4nzsSiulRopIELol+A4Qbe6X3yjgfgEQkcroLvWmgsp/zgcU9DiBQjfzEZE70C2UwvgWPd5ym1nO4jNgsGm9iIiUFpFrRKSMiNQXkSvMSTnBmQE50E/aGjkChjN/o59ET4lIgIh0AnoB37tTWcOPwDUicqWIBKAH+E6i++r/oPvhI03ZS4lIe7NfGXT3MclcIPndcK7gSVt58QnwjIg0BhCRcBHJ93W1iLQ25ywAPb50gjPnJie/obuwnuAgECki4U7bvgOeF5EoESkPvIhuwRWIiASKyG0iEq6USkOPWWTVoQcwPccuU4CWwCPAOKft44FeInK1iPiZa6CTiFRBB4Ug9P2SLiLd0eNZhdERmKeUOllQpnM+oCil1gPvAkvQJ7cJuilY2H5/oy+8GHR/PWv7cuAedPP5MHpgcJBJDgJGokfTD6CfIs+YtKyPvRJE5N88/J1CB5DuZv/R6HGbjS5X9oytTegn00fGVi/0iP8p0/rqhR7v2Y0ese9rdn0FfQEmoS/On9317YQnbeVCKTUZ3fr73nSp1qGPXX6EoR8Gh9FdjATMdyZ58CvQwI3uakHl3IgOINtN9yIGeA1Yjm4JrQX+NdtcYQCw09R5MPqBB3m8LlZKpaJbGzVxOv5KqT3oQdpn0YFjDzrgO0xL/GH0Q+kwcCsw1YVy3YYO8gUiZrDFYrmgEJF7gUZKqUeLuyyFISLRwEr0gLbKkfYiUE8p1d+L/psCnyql2haa1wYUi6VkIyL1gFZZ43hO28uhA80ApdTCYilcDs75Lo/Fcr6jlNqcRzC5B92VmVFSggnYForFYvEgtoVisVg8Rkn9RzmfE+gfooIDwgvPeBacCvfR4S7qlyVuoELyeyPrOQK3p3rdR1rtUl73ARCwLa/vxDxLCofjlVJRXndUADagGIIDwmlb5y6v+th7daRX7WehfHBW01unFJ7pLKl201qv+9j3biOv+wCIuW691338ribtKjyXd7FdHovF4jFsQLFYLB7DBhSLxeIxbECxWCwewwYUi8XiMWxAsVgsHsMGFIvF4jHsdygu0Kp9Xe4f1gOHn4OZP6/gx7HZ/3UiqmI4T75+A6XLlMLPz8EXo2az7M/NLtuvGB7KG7d0I7JMCErBpKVrGb9oZZ55L6oazfiH+jF0wm/MWbPFLR8jbu5GZGgICpj4z1rGL87uo3WtKnx0e29iE5MA+P2/rfxv7t8u+wh0+DGh4yACHX74ORzM2ruBjzYsyJYnJiScN1r1plxQCEdOpTJ02WQOprr3TcvFVzfngVF34PBzMGPsXH54c0q29IBAf576egh1W9UiOSGF1/u9z8FdcflYKxgHwo8d7+PgiWQe/PvbbGkBDj9GtLyexuGVOJKWyhPLJrIvtcAJzYq1Lr7gnAooIjIfPQv4cl/5dDiEB5/rxbP3fkn8gWQ+/H4wS//YwO7tZ07qLfd1YuGsdUz/8R+q1Ypi+OjbGdjtXZd9pGcq3v51IRtiDxESFMCPj97GX1t2sf1gYvayiPDYNR34a7P73y+lZyremr6QDfsOERIYwMQht7Fkyy62HcruY8WOWB78+he37QOcysxg4MJxHM9Iw18cfNvpDhYe3MrqxDOT0g1r0oUpu1YzZfca2kTV4InGV/LU8ikFWM2Ow+FgyMd3MazrcOL3JvLxPyNYMnU5uzeckcbpdtcVHD1ylEH1htCpbzvuHtmf1295v0h1GlC7DduPxlHaPyhX2g3VWpJ8KpXucz+ke+WLeLxxF55c7roGmq/r4gsumC5PUbVh6jepwv7dCRzYe5j09AwWzFhL284Ns2dSEBKqL7jSZUqREOfeEzc+5RgbYg8BcPxkGtsPJhIdlnsK01s7NGfOmq0kHj3udj3iU46xYZ/xcSqN7XGJVMjDx9lyPCMNAH+HA39xkPN/T2uHlWdp3E4Alsbt5MqY+m7Zr39JHfZtPcCBHYdIT0tn/g+Ladfn4mx52vVuzeyvdcto4aSltLjSlQn8chNdKozLo+vx065c82UBcEWlBvyyZxUAs/etp035mm7Z92VdfIVbAcVMBr1GRFaLyDci8pWI3OiUftRpeZiIrDV5R5pt80XkYrNcXkR2muVBIjJFROaIVgp8SEQeF5GVZjLdck7FGGAmpF4nIpeY/UuLyBci8o/Zp4+T3akiMg+YW5QDFFkhjLgDSafX4w8mExmdfe7j8aPnckXPZnzz+1BeHX07o0dMK4orAGLKhtGwchRrdh/Itr1CWGmuvKgOPyxZXWTb2XzERLFmz4Fcac2rVeLnR/rzyR3XUruC+/8q4ECYcuW9/NXzSf46tJ01h7NPmbvxyEG6Vm4AQJeYBoQGBBERGOyy/fKVyxG3N+H0evzeRMpXzl7OyMrliNsTD0BmRibHko4TFlnYnNS5ebpJN979bzaZ+fxHfoVSZTiQmgxAhsokJf0kEYEhLtv3ZV18hcsBxczt+TxauqAZeh7L/PJ2R09Bd6nJ+5YLLi4CrkdPxvs6cFwp1QI9tePtTvlClFLN0TPff2G2PYee7/ISoDPwtoiUNmktgRuVUrnmEBWRe0VkuYgsP5Xh/lM/i049mjJnykoGXPU2Lz4wjqFv3IieN9o9ggMDeH9gT978ZQHHTp7KljasTyfen/5nrie+u4QEBjDqtp6M/DW3j/Wxh+jy5liu/2A8E/5axUe3F6o8mYtMFNfOHUPH396nadnK1A3L/r9qb62dQ+vy1Zl85T1cElWdA8eTyVDe/0dDd+kYXY/Ek8dYn7S/uItyTuFON+AKYKJSKh5AKZVYwE1zFfClUup4Vl4X7P9h5rtMEZEk9LyfoOfkbOqUL2v2+YUiEmYkBLoCvUXkSZOnFHqmcYA5+flXSo0BxgCEB1fK81ZNOJRMVMUz/4VcPjqMhIPJ2fJcfV0rnhus5wjesHoPgUH+hJUNISnxmAvV1vg7HIwa2JPp/27k93Vbc6U3rhrN2/17AFC2dDCXNaxJRkYm8/7b5p6P/j2Zvmojv/+X24dzgPlz005euNZBREgpjhx3/z9lU9JO8nfcTi6LrsOW5DPjTYdOHGXIUj3OEOIXQNeYhqSkFTjvcTbiYxOJqnLmKV6+SjniYxOy5UmITSSqanniYxNx+DkoHR5CcoJ73dAW5arRqWJ9LouuS5DDn9L+QYxseT1P/3tm6txDJ1KoGBzGwRPJ+ImDMv5BHDnl+oPJV3XxJWc7hpKeZcPM9h7oan70Te+M81WV6bSeSfbAl/PGV+h/2L9BKdXc/KoppTaYdNfv6jzYtC6WmOqRRFcui7+/Hx27N2Hp/OzzSh86kESLNrUAqFozisBAf7eCCcCrN3dh+8FExi3Mu7/e7Y0vuNr8Zq/Zwms/z3MrmAC8emMXth9K5OtFefsoH3qmud6kSjQOEbeCSdnAEMoE6LGkIIc/7aJrsT0lPkee4NOzK9zboAM/7VrlVh02LdtK5bqVqFijAv4B/nTq254lU7OP0S/5dTldB+oG6eU3tmHVvHVu+QAYteF3rpz9Hl3njOLJ5ZP4O35HtmAC8MeBTfSp2hyArjGN+Dt+R4msiy9xp4UyD5gsIu8ppRLMuMZOoBV6Bu3eaGlF0BKRL4rIBKXUcREpZ1oJWfn/AW7M6cBF+gJ/iEgHIEkplSQis4AhIjJEKaVEpIVSKu/3rm6SmZHJ6Dem8fonA3H4OZg9eQW7th1iwINXsuW/WJbO38hnb8/gkZev5boB7VAK3n3evQngW9SIoffFjdi8L45Jj+lJzj+YsZhKZfVYzY9L1px1PVpWj6FPy0Zs2h/HTw9rH6NmLaZShPHx9xq6NqlL3zbNyMjM5ERaOk9+654md4VSoYxs3Qc/cSAIM/euZ/6BLTzcqBPrDu9j3v7NXBJVg8cvugKlYHn8Ll5ZNaNww05kZmTy8ZCxjJj5HA4/B7O+/INd6/cy8JW+bF6+jSW/LmfG2Hk8PW4IX23+iJTEox59K/JQg878d2QffxzYxE+7/mVky+uZceXDJKWl8uTySedUXbyBW1NAishA9HT8GejJcYcBv6D1X2cCDyqlQk3ep9FjH6eA35RSz4pIA3TwyUBLL/RXStUQkUHAxUqph8y+O816vHOaeW28Cq0REoCWuvxHRILRgtTt0C2gHUqpnjntFkR4cCVl50NxnfNmPpTJ59V8KCuUUhcXntN72DllDTaguIcNKO5xoQSUC+Y7FIvF4n1sQLFYLB7DBhSLxeIxbECxWCwewwYUi8XiMWxAsVgsHuOcmr7Am5wK9/f6a91K7/3lVftZ+OJVaPU3/LzuY/cL7bzuo+p1vjknFwq2hWKxWDyGDSgWi8Vj2IBisVg8hg0oFovFY9iAYrFYPIYNKBaLxWPYgGKxWDyGDSgWi8Vj2A/bCsEXIlzgO8EnbwtXPf58L9q0r8eRw8e499ZP8szzwONX07pdXU6eSOOd4b+wdVPu2ffzo2JYKG9e343I0lqw7McVa/lmafbzcWf7VvRqomfW93M4qB1VjnZvfUJSqutz14Jvzsn5JvTl9RaKiESIyANe9tFJRLzyWWWWCFeft8dx60ff0a99M2pFl8uV72xEuLIEn57t8Tp3N36Mzv3aU61hlWx5nAWffh41jbtH9i9SfbKEq/LCWbhq3LYlPN64i9v250xbzbOPTsg3vXW7OlSuGskdN37MqJHTePipa9yyn5GpeHPWQnr+3zj6ffYdt7VuRu2o7Ofji8UruO6TCVz3yQTe/30xy3budTuY+OKc+PK8+wpfdHki0JIX3qQTevpHj+MLES5fCT55W7gKYO2q3aQkp+ab3u7y+syZobWFNq6LpXSZIMpFui44Fnf0GOv36/Nx7FQa2+ITiS6T//7XNKnP9HWbXLafhS/OyQUv9FVERgK1jTjX2+a3zoiA9YXTLYwFIvKLiGwXkZEicpsR7lorIrVNvl4i8rcR8/pdRKJFpAYwGHjM+LhMRGqIyDwjSjZXRKrlWzo38JYIl68En7wtXOUKkVFliHOSIYk/lEJkVNGEqypHhNGwYhSrY/PuMpUK8KdDnRrMXu9e9xN8c04uaKGvs+BpYJsR51oKNAeaobV73haRSiZfM3RgaAgMAOoZ4a7PgSEmzyKgjREA+x54Sim1E/gEeN9IaPwJfAR8rZRqCkwAPsyrYM5CXxnHC5a98IUIlzc534SrQgID+LBvT0bMzH0+suhcrxYr9+xzu7tjKTq+HpTtAHynlMoADorIArRSYDKwTCm1H0BEtgGzzT5r0WqAAFWAH0wQCgTyE0Jpi1YhBPiGfJQLnYW+gitWzTcceFuEyxeCT74QrnKFhLgUopykXMtXKOO2FrS/w8GHfXvy65qNzNmQ+3xk0aNJfaav3ZhvekH44pxYoS/v4orQ10fAx0qpJsB95BYL8wreFuHyheCTL4SrXGHJn5vp0r0ZAA0uqsyxoydJTDhayF7Zea1PF7bFJfLVkrzPB0BoUCCtq1dh7kb3xNCy8MU5udCFvopKCpDV6fsTuE9EvgbKAZejdX4auGgrHMhS3x6Yw4ezgvlfQD906+Q247dI+EKEqzgFnzwpXAXwzPDradqyOuERIUz49VG+GTMfP389d8r0ySv4Z/EWLmlXh69+esi8Np7qlv2W1WK4tnkjNh2IY/JgfT7en7uYSuH6fPywXJ+PLg3rsHjbLlLT0t2uA/jmnFzwQl9FdiLyLVqfOEsmrjtaQvQ1pdQPItIJeFIp1dPkn2/WlzuniUgf4H3gMFrJsLVSqpOI1AMmoVszQ4DdwJdAeSAOuEMptbugMgZXrKpq93/cg7XOzfk0wVJlX0yw1M37g49Vh58/EyyVBF0en4yhKKVuzbFpaI70+cB8p/VOeaUppX5BKxXmtL+Z7ILqoMXdLRaLDylJYygWi+UcxwYUi8XiMWxAsVgsHsMGFIvF4jFsQLFYLB7DBhSLxeIxbECxWCwew06wZAg4mknFpQX/g+DZsv9x7yvhAVR9PqHwTGfJ0ffyn6LAU5SZ4Pq0BkUlc25Vr/sAcFy5xyd+ihvbQrFYLB7DBhSLxeIxbECxWCwewwYUi8XiMWxAsVgsHsMGFIvF4jFsQLFYLB7DfodSCE8+05NL29XlyOFj3HP7mFzpVatFMvTZXtSpV5EvP5vPxO+Wuu3DV2JirdrX5f5hPXD4OZj58wp+HLswW3pUxXCefP0GSpcphZ+fgy9GzWbZn5vdro8D4fNLHybuZDLDVn2ZLa1PlTZcX6UtmShS00/y1oaf2HnskFv2X7izKx2a1+Jw8nH6PT8uV3qZkCBeuOtqqlQI51RaBsPHzmJbbNG+zXEgjL74MRJOJvHc2rF55rksqikvXzSI+5e/x+aUvW7Zt0JfRUBECpw0NKcYmJHByDkpU7Ew67c1PPPEd/mmpySn8n+jZjHxe/cDSRa+ERMTHnyuF88/MI57+3xIp+5NqFYrKlueW+7rxMJZ63jo5tGMGPoDDz3Xq0j1ualaB3blEyTm7F/JwKXvc8fSUUzYtYAh9dz3MW3Rfzz87s/5pt/R61I27z7ErS98w0ufzeCJ2zrnm7cwrq96ObuP5x/wgv2CuL7KZaxPKtkCb76ipHR5coqB1QBKREBZu7pg4aojR46zaeN+MtIzi+zDJ2JiTaqwf3cCB/YeJj09gwUz1tK2c8PsmRSEhAYBULpMKbdnoweICgqnbfkG/Br7T57pxzPOzEUe7BeIwv0pSFdujiX52Il802vGlGP5Bv1l6q79h6lUPoxyYe7rC5UPCufSyIb8ti//h8UdNbvz/e55nMpMc9u+FfryACIyVESWGRGuV8zmbGJgZv0ys/6YiAwSkY+dbEwzc80iIt1E5F8RWS0ic8220iLyhREKW2nmoj0n8JaYWGSFMOIOJJ1ejz+YTGR0WLY840fP5Yqezfjm96G8Ovp2Ro+Y5rafh+v34n9bfiswUFxfpS0/tB/G/XV7MGqTe5NUu8KW3XF0blUHgEY1K1IxMowKZd3/jP/BOtcyZuu0fOtSN7QyUUER/J2woUjltEJfZ4mIdAXqApegBb9aicjlOImBKaWGmvU/zXq+03yLSBTwGXCDUqoZcJNJeg6YZ4TCOqMFxUrnsf9poa+0dO/+H48rFLeYWKceTZkzZSUDrnqbFx8Yx9A3bkREXN6/XfmGHDl1lE0psQXm+3nvEvoufpNPtvzGwJqen/r36+nLKBMSxIRX+9O3S3M27zqUr1pifrSJbMThtKNsOZr3mIggDK7Th0+25Zri+ILG14OyXc0va8QxFB1gCpyRvgDaAAuVUjsAlFKJTn56i8iTZr0UUA3I9ihxFvoKC61crLp/3hYTSziUTFTF8NPr5aPDSHCSBAW4+rpWPDdYD3JuWL2HwCB/wsqGkJToWrBtElGd9lGNaFO+AYGOAEr7B/HCRf0Yvu77PPP/fmA1TzS4ziXb7nDsxCleHTv79Pov79xF7KGkAvbITePwmrSLbMylbRoS6PAnxL8UzzS8jREbtBB8iF8QNUtX5L3mDwJQLrAMw5vcxQtrx7o8MHs+Cn35OqAIMEIp9Wm2jVqfuCDSyd6aKkzgS9CtFvdVsosJV8TEsnitb1cWbNjhnpjYulhiqkcSXbksCQeT6di9CW8Om5gtz6EDSbRoU4s5v6ykas0oAgP9XQ4mAJ9uncmnW2cC0KJsLfpV75grmFQJKc/e47oJ3658A/amev4/o0NDgjhxMo30jEyu7diElZtiOXYib7nS/Bi7fTpjt08HoFlEbW6u2ul0MAE4lnGC6xe/eHr93eYP8Om2qW695XEW+oqPTaRT3/aMuO2DbHmyhL42LN1shb7yYBYwXEQmKKWOikhlII3sYmDksb4TeEBEHEBldJcJtFbyaBGpqZTaISLlTCtlFjBERIYopZSItFBK5f0ethCeffk6mjWvRnhECN/9/DBfj12Iv7+ObdN++Zey5Uoz+vO7CCkdhMpUXH/TJdzV/xOOH3f9AvaVmNjoN6bx+icDcfg5mD15Bbu2HWLAg1ey5b9Yls7fyGdvz+CRl6/lugHtUArefT7/NynucFftrmxM3sviuPXcULUdF5erQ7rKJCUtldfX/eC2vdcG96BVgypEhAYz7b17GDNlCf5++pz8/McaalYqx0v3dAOl2B6bwPAvZhdi0XUG1ezGpuQ9LEn476xtWaGvojoROaqUCjXLjwB3m6SjQH+l1LYcYmDPooNCJPAVMAoYD7RCd1vKAi8rpeaLSHfgDXQL5pBSqouIBJt92pntO7JExPIjLLSyuqT5/R6sdW4OtMk1jOMVqszyxXwo7j3xi8LJCRW97iNsoHvfjRQVX8yHciEJfYU6LX8AfJBHnpyviXOO1t2Wj+0ZnFEkzNqWitY+tlgsPqSkfIdisVjOA2xAsVgsHsMGFIvF4jFsQLFYLB7DBhSLxeIxbECxWCwewwYUi8XiMewESwZJyyBg/xGv+qj0XtH+U9htypb1uovgqw973ce+d6K97iPiAhHg8hW2hWKxWDyGDSgWi8Vj2IBisVg8hg0oFovFY9iAYrFYPIYNKBaLxWPYgGKxWDyG/Q7FBVpdXp/BL/TRAlk//M3ET//IleeyHs3o/3BXlFJs37iPtx771i0fvhB8anVFY+4f0ReHw8HM8Yv48YOZ2dJ7DLqcXnd1JjMjkxPHTvLB49+we9P+ElePQD8/fujbl0A/P/zEwcwtWxi15K9seVpXrswLnTrTICqKR6ZPY8YW90TRfFUXK/R1geFwCA++fB0v3Pk59139Np16taBanewfXMXUKE/fwVfwxM0fM7j7O3z6mnvSEL4QfHI4hAffupXnbwqqd1MAACAASURBVP6Qe9u9RKfrW1OtfqVseeb/9A/3X/YKD3YazsSPZnHv8JvysVZ89QA4lZHBbRMncs0339Bz/DdcXqMGzStlr8u+lBSemjWTqRuLJnHhm3Nihb68hoiUyNZSvWbV2LcrgQN7EklPy2DBtFW0uapxtjzd+l7Kr+MXc9QIgiUlFCiUmAtfCD7Vb1mT/TsOcWBXvK7H5GW07d4sW57jKWfEs0qFBLot2eFL4arjaVpYy9/hwN/hIOdUprHJyWyMj3dbPiMLn5yTC1XoS0SmiMgKEfnPaNn4ichXIrJORNaKyGMm33wR+cAIdK0TkUvM9ktEZIkR3fpLROqb7YNEZKqIzAPmikioiMw1wl1rnQW6ROQFEdkkIotE5LssiQzj82KzXF5Edprlxkboa5URFatblANUPjqcOKdP8uMPHCEyOjxbnso1o6hcM4p3fnyQ9ycNodXl9d3z4QPBp8hKEcTFJp5ej993hMhKuT/R73VXJ75Y/jp3vXwD/3smb/mL4qxHFg4RpvUfwLLB97N49y5WHzhQ+E5u4Iu6nI9CX662Cu5USiWayZ+XASuAykqpi0BrEzvlDVFKNTcCXl8AFwEbgcuUUukichV6UukbTP6WQFNj3x+4TimVLCLlgaUiMhW42ORvBgQA/5oyFMRg4AOl1AQRCQT8XKyr2/j5OahcozzDbv0f5StG8Pb3D3B/93c4lpK/XGZJ5dex8/l17Hw63XAJtzzRg3cf/Kq4i5QnmUrRc/w3lAkK4pPevakXGcnmBO9Pzm0pGFe7PA+LyGq0bEVVIBCoJSIfiUg3wFkx6jsApdRCIMwEm3BgooisA94HnPsMc5wEugR4Q0TWAL+jJTOigfbAL0qpE0qpFOBXF8q8BHhWRIYB1c3E1dlwVg48lZm3XnD8wSSiKp2Jl+UrRpBwMLtoVPyBJJb+vp6M9EwO7k0kdkcclWtE5TSVL+4IPgFFEnxK2H+EqMpnBNjLx0SQsD//f/Bb8PMy2vVo4bJ98E09cpJy8iRL9+zh8ho1i2wjL3xRl+I4Xt6m0IBiNISvAtoauc+VQBC6tTAf3RL43GmXnJ1WBQwH/jAtml5kF+pyVpK6DYgCWimlmgMHKVzUy1kE7HRepdS3QG8gFfhNRHJpXiqlxiilLlZKXRzoyFtMe/OaPcTUKE90lXL4B/jRsWdzls7NrsmyZM46mrapDUBY2RAq14xi/x7Xn5bOgk/+Af506tueJVOXZ/dhBJ+AIgk+bVq5k5haFYiuFqnrcV1rls7I/t/PMbUqnF6+pGsTYrcfdM+HD+oBUC44mDJBWtQ9yN+fDtWqsz0xsZC93MMn58RHx8uXuNLlCQcOK6WOi0gDtPxnecChlPpJRDahNXOy6Av8ISIdgCSlVJKIhANZgreDCvF1SCmVJiKdgepm+2LgUxEZYcrcEyMhihYBawX8A9yYZUhEagHblVIfikg1tObPPBfqm43MjEz+98pkXvvqHvwcwuxJy9i95SADHr2azWv38Pfc9axYuImWHerx6cyhZGRmMnbkNFKO5N3iyc+HtwWfMjMyGT3sO16f+KgW+vp2Mbs27WfA073ZsmoXS2eupvfdnWnRsSHpaRkcPXKcdx/40m0fvhCuqlC6NG93646fCCLCb5s3MW/Hdh5t1461Bw4yd/s2mkZH87/efQgvVYora9Xmkbbt6Dbu6xJVlwtS6EtEgoApQA1gExABTAYGcqZl8IxSaoaIzAdWAR3RYx13KqX+EZG2wNfo1sh0tLhXDREZBFyslHrI+CqP7s6EAsvRwau7UmqniLwM3IputRwCZiqlPjNB7kcgI4ftp4EBaGXCA8CtTl2rXIQHVVTtqnj3lVz6jl1etZ+Fnw/mQ8k47P35ULa908brPmo/udTrPnxFSRD68qhyoAkoTyqllheWtwi2Q418aQiwELhXKZW3EHARsAHFPWxAKXmUhIBSIr/9yIcxItIIPU7ytSeDicVi8QweDShKqU6etJfDdk6pUovFUsIoMV/KWiyWcx8bUCwWi8ewAcVisXgMG1AsFovHsAHFYrF4jHPptbF3EUEFePdwHL3Z+99VAEQsc29SpKKwd3BDr/sos93rLpi89x/vOwGuq3KJT/wUN7aFYrFYPIYNKBaLxWPYgGKxWDyGDSgWi8Vj2IBisVg8hg0oFovFY9iAYrFYPIYNKBaLxWPYD9tcoFWHetz/XC8cDmHmpGX8+NmCbOn3Pt2TZpfWAiAoOICIcqHceMkrLtt/7r6radeyFoeTj9N/aO5pCm/reTFdO+gPyfz8HNSoXI4e9/yP5GPuzarvbQXEiuGhjLyxG5GhIaDgx2Vr+WbJylz5WteswjPXdCTA4cfh46nc/vlEl31ER4Ty+u3dKFdGzwE8afFavp2f3UePixtwR5eLERGOnTjF6z/MZXNsvMs+TiNhlIp4E4d/PQBOHBlKZtqZaXj8g68lIHQwIKCOcfLIc2Smuycsdr4pB5b4gCIijwJjlFIFTtLqaj53cTiEB1/sw7N3jiX+YBIfTnyIpfM2sHvbodN5xoycdnq5d/921G4Y45aP6QvWMXHWSl58sHue6ROmLWfCND0JXoeWtejbo5XbwSRLAfHZgWOIP5DEB5Mf4e+569m99cxE1M4KiEeTUwmPDHXLR0am4q0ZC1m/7xAhgQH89OBt/LV1F9vizsy8WaZUEC/2voJ7v5rM/qQUypUOdtvHOz8vZOPeQ4QEBfD9sNtYunEX2w+c8RGbkMSdoyaSknqS9o1q8OItV9H/Hfc0hgCCwl8i/eQC0g/fDwSAZC9rZvoeUuNvBpWMX1AngiJGkBp/rcv2s5QDh3UdTvzeRD7+ZwRLpi5n94a9p/M4Kwd26tuOu0f2L9Hzyp4LXZ5HgbynpC9aPreo37Qq+3cncGCvUQ78bTVtr2yUb/5O1zRj/vRVbvlYtTHW5QDRpX0D5vy10S374BsFxLiUY6zfpwPt8VNpbItLJDose1Dq2aw+v/+3lf1JWgoi8VgudZMCiU8+xsa9xsfJNLYfSKRCRHYfq3fsJyX1JABrduwnOqIIwlhSBr/AS0k/nhWI0kAlZ8uSmbbi9LaMU/8ifpVwhwtWOdCTiEgNEdkoIhNEZIOITBKREBG50igLrhWRL0QkSEQeBmLQs+j/Yfb/n9HS+U9EXjHb8sp3i7G1TkTeLGp5I6PDiNt/Rocn/kASkdFheeatEBNBxcplWb10W1HdFUhQoD9tmtVg/t/uC3/7QgHRmZiIMBpWimL13uyKfjUiyxIWHMTXd93IpAdupU/zov9PUEy5MBpUiWLtzvxVA69rdxGL1u9w27bDryoqM4GgiHcIjvqNoPA3c7VQnAkI6UfGiflu+TgflQOLq4VSHxitlGqIFgl7HPgK6KuUaoLuit2vlPoQ2Ad0Vkp1Nvs+ZybibQp0FJGmOfOJSAzwJnAF0BxoLSK52qLZhL4yzr6n1LFHM/6cvY7MTM9N/O1Mh1a1WbNpn9vdHVdxVkAc+egEHnnjJkqXKUwWKTchgQF8eGtPRk5fwLGTp3L5aBwTzeBxU7j7q5+5v/Ol1IiMyMdS/gQHBvDu3T15+6cFHDtxKs88retW4bq2jRn1yyK37SN+OAIuIu3YeFLjeqDUcQJDH8gzq19gWwJC+nIyeYT7fs4ziiug7FFKLTbL44ErgR1Kqc1m29fA5fnse7OI/IsWHGsM5NX/aA3MV0rFKaXSgQl52csm9OWXd28p4WAyUZXOPMnLVwwn4WBynnk79nC/u+MOXdrWL1J3B3yjgAhavPyDW3vy6+qNzFm/NVf6gaSjLNq6i9S0dI4cP8HynbHUr+S+j/fu6clvyzcyd3VuHwB1Y8rz0q1deHTMVJKKEIBVxgFUxn4y0/T5TD/xG46A3N0Nh38DgiLeJDXxblBHcqUXxAWpHOglcj7CXToTIlITeBK4UinVFK3D4/4j1A02rd1LTPVIoiuX1Yp7PZqxdN76XPmq1IyiTHgwG1bu9ko5SgcH0qJRFRYuz/sGKgxfKCACvHZ9F7YfSuTrxXmLEszbsI2W1WPwcwilAvxpWrUi2w+5p/r38m1d2H4gkW/m5e2jYtkyvHdPL54bN5Ndh9y7ybNQmXGojP2In3575x/Unsz07F1N8YuhVLlPOXH4MVSG+92qC1U50BtUE5G2SqklaPGu5cB9IlJHKbUVLdCV9W42BSgDxANhaLGwJBGJBrqj5VBz5vsH+NAIhx0GbgE+KkpBMzMyGT18Kq+PvROHw8Hsn5aza+shBgzpwpZ1e1n6h35NqAdjVxdiLW9eGXINLRtVIaJMML/83718Pukv/P10rJ/8+xoAOl5Sl7/X7OLEyfQi+fCFAmLL6jH0adGITQfi+Pmh2wAYNXsxlSL0mNMP/6xhe1wiizbvZMqQASilmLR8HVsOuR60WtSKodeljdgcG8cPT2sfH01dTKVy2sfERWu4r/ulRJQuxbN9tfpsRqbi1rdcf/2dxcmklyhV9gOQAFT6bk4ceRL/EO0z/fgEAkMfQRxlCYoYrndQGaTG93LZ/gWpHOhxhyI1gJnoINIKWI8OIG2Bd9BBbhl6DOWkiAwBHgL2mfGRr4B2wB4gCZiqlPoqj3y3AM+iBdinK6WGFVSu8FKVVNsaAz1d3WwkNXevaV9UfDHB0s5+lb3uIzCp8Dxny+JnR3nfCb6ZYOlCFvpKV0rllOmbC7TImVEp9RFOrQul1KC8DOaR7zvgO08U1mKxuMa58B2KxWI5R/B5C0UptRMo2V/nWCyWImFbKBaLxWPYgGKxWDyGDSgWi8Vj2IBisVg8RomfvsBXZAb6cbKq+/9T4g4hB0961X4W6Tt2ed1HlRHe9+ELLqr/sE/83Llmvtd9/N7E6y4KxbZQLBaLx7ABxWKxeAwbUCwWi8ewAcVisXgMG1AsFovHsAHFYrF4DBtQLBaLx7ABxWKxeAz7YVshPPVED9pcWpsjR45z571jc6W3b1uXOwZdhlKKjIxMPh49l3X/7c3DUv48+dQ1tGlThyNHjnP3nZ/lSr/yqsb069cWBFKPn2LUqJlsd9IFchVfiEqdLz6C/Pz44Ya+BPn54ScOZmzbwvt//5Utz13NW9GvcRPSMzNJTD3OU3NnEZvi3nyvD9f7nJOZqSiVSSYZfL7t8WzpkYFV6FPlESqWqs0fB79hScJkt+z7mhLZQhER9wRh8rfTXER6nI2NmbPXMuzZH/NNX7FyJ3ff9wX3DP6St975jaGP5y3WVRCzZq7hmWH5C1Ht33+Exx4dzz13fc74bxbx+BPu+8gSlXq2x+vc3fgxOvdrT7WGVbLlcRaV+nnUNO4emXMOrAvDB8DJjAxunTyR7t99Q4/vv6FjtRq0iM6uu7M+7hC9fhhP9+/GMWPrFp5p39FtPwDjdjzHmG2P5AomAKkZKczcP4Yl8SU7kGRRIgOKB2kOnFVAWbN2D8kp+c+afuJE2unlUqUCULnm3y6ctWv2kJycv4/1/8Vy9KhOX79+H1Hl89YFKghfiEqdLz6yOJ6mz62/w4G/w5Hr3C6J3cOJdD3H78oD+6lY2j2lRZfKkJHEvtQtZFK0uYR9TbEEFBEZasS5EJH3RWSeWb5CRCaY5ddFZLWILDUTUiMiUSLyk4gsM7/2ZvslIrLECIX9JSL1RSQQeBXoKyKrRKSvt+rToX09vh57DyNeu4m33vnNW24A6N6jGf/8476QmC9Epc4XH1k4RPit3wBW3HU/i/bsYtXB/AXFbm58EfN3uT/zvQL613iVu2u/T8uyV7u9f0mjuFoofwKXmeWLgVARCTDbFgKlgaVKqWZm/R6T9wPgfaVUa+AG4HOzfSNwmVKqBfAi8IZS6pRZ/kEp1Vwp9UPOQjgLfaWlHStyZRYt3szAuz7jhZd/5s5B+ckJnT3Nm1ene49mfDYmt8i5xfNkKkWP77+h7ZdjaBZdkXrlIvPMd239hjStEM2Yf5fnmV4QX21/is+2Pcq3O1/m4nLXUC2kceE7lWCKK6CsAFqJSBhwEliCDiyXoYPNKWCaU94aZvkq4GMRWQVMBcJEJBQIByaKyDrgfbQAWKE4C30FBJQ+60qtWbuHSpUiCAtzTwDcFWrViuKJJ3vw4vOTSE52Tw8YfCMqdb74yEnyqZMs2buHjtVr5kprX7UaD118KXdPm8KpzAy3baeka02i4xlJbEpZQuXgekUuZ0mgWAKKUioN2AEMAv5CB5HOQB1gA5Cmzuh7ZHDmbZQDaGNaHM2VUpWVUkeB4cAfSqmLgF54WfzLmZiYM1Me1K0TTUCAX5Fu+IKoUCGMl1+9gREjprJ3r3uiWFn4QlTqfPEBUK5UMGGBQQAE+fnToVp1th3Ofuwbl6/AG527cPe0KSSkun/OAySIQEfw6eVaoS04dPLcnhaiOF8b/4lWAbwTWAu8B6xQSikRyW+f2cAQ4G3Qb3GUUqvQLZRYk2eQU/4s8a8i8/yzvWnetBrh4cH8+O0DfDVuEX7+Og7/Om0Vl19Wn6uvuoj0jExOnkzn1dd+cdvHc8/3oVnz6oSHB/P9jw/x9Vd/4meEvqb9upIBt3cgLCyYRx7tBkBGRiYPDP7SLR++EJU6X3wAVChdmne7dMchgkOE6Vs2MW/ndh67tB1rDx3k9x3beKbD5YQEBDC6uxb3ik1J4Z7pUwqxfIbS/hHcXO05ABzix7qkBWw7+i+tyurzvOLwTEr7R3BP7fcJcoSgyOTS8r0ZveUBTmV69qHlKXwu9HXasciVaMGvCKXUMRHZDHyilHpPRI4qpUJNvhuBnkqpQUYJ8P+AhuhguFApNVhE2qL1kI+h5Un7K6VqiEg5YBYQAIzIaxwlizJhVdTFlz7kxRqDIz3Tq/ZP+1mw0id+zge2fNDGJ37u7Dzf6z5eajLtghX6Qik1F32jZ63Xc1oOdVqeBEwyy/FArrc1RtLUufP5vNmeiBZOt1gsPuB8/w7FYrH4EBtQLBaLx7ABxWKxeAwbUCwWi8ewAcVisXgMG1AsFovHsAHFYrF4DDvBkkGOphKwcK1XfSQMaOVV+1mUW+B9H6e6ef/znsCZy7zuI2pFvl9le5Tnb9rodR8ved1D4dgWisVi8Rg2oFgsFo9hA4rFYvEYNqBYLBaPYQOKxWLxGDagWCwWj2EDisVi8Rj2OxQXuLhrU+5/dwAOPwczv5jPD+/8mi29SYcGDH6nP7WaVOON/h/z5+R/3LIfXTaUV+/qTrmwEJRSTF64lu/m5p4kaegtnWnfpCYnTqXx8hez2LjbPbEvXwhkDXu0G20vqc3hI8e544H8Z5VrULci//def14dOZUFizeXuHq8cGdXOjSvxeHk4/R7flyu9DIhQbxw19VUqRDOqbQMho+dxbYcc9u6hJRBwt8A/7oAqKSnIW3VmfSgK5HQR9Hz46ejkl+HtBXu+/ERxSWjUcNMKF3U/V8WkSc9Wab8cDiEhz4YxHO93+KeZk/RqW9bqjWonC3PoT3xvHP3p8z7/q98rBRMRqbi/R8XcNOLXzPoje+4qXNzalYqly1P+yY1qVohgmuf/YLXxv3OM/2vdLMevhHImvH7Ooa+MKmQsgj33dmR5f+6Lzvhq3pMW/QfD7/7c77pd/S6lM27D3HrC9/w0mczeOK2zm77AJCw51EnF6Liu6Hie0F6DomUU0tQCb1QCb1RSc8g4a8XyY+vOOe6PCLi01ZV/da12bftIAd2xJGelsGCH5fSrlf2L14P7opnx7o9qMyiTacZn3TsdGvj+Mk0duxPoELZ7KJRHZvXZvqS9QCs276f0JAgyoe7PlO/rwSy1qzbS0pKwfOdXt+rJQsWb+bwkeNu2/dVPVZujiX5WP7iazVjyrF8wx4Adu0/TKXyYZQLC3HPiYRCQGtInWg2pIHKMTu/cjpG4nk1BU9TnAHFX0QmiMgGEZkkIiEi8qIR8FonImPEzFYtIvNFZJSILAcecTYiIrVFZKaIrBCRP0WkgYiUEZEdRusHEQlzXneH8jHliNtzpikbF5tIZOWyZ1fzAqgUGUaDahVYtz27qFSFiFAOJp652A4dPkpUhOtKdb4UyCqwHJGhXNauHr9ML9q8tyWlHlt2x9G5VR0AGtWsSMXIsFwPgULxqwqZiUj4m0jkL0jY63kHjaAuSPmZSNnPdJeoBFOcAaU+MFop1RBIBh4APlZKtTZyGMFAT6f8gUZD590cdsYAQ5RSrdCz6I9WSqUA84FrTJ5+wM9GvuM02YS+VP5PI18RHBTA2w/04p0f5nPsxKniLo5XGHLvFXz6xXyKaW50j/H19GWUCQliwqv96dulOZt3HSLT7Ur5QUBj1PFvUQl9QKUipe/Lne3kHN0lOvyAGU8puRTnoOwepdRiszweeBjYISJPASFAOeA/IGsENC/lv1CgHVrkK2tzkPn7OfAUMAW4gzPqg6dRSo1BByTCHJF5Xg3x+xKJqnrmCRhVuRwJsYddrqSr+Ps5ePv+XsxYuoE//t2aK/3QkaNElzvzlK1QNpS4I65ryrsjkBUfm+gRgay8qF+3Ii8+3RuA8LBg2rSuRUZmJouW5K5zXpSUehw7cYpXx84+vf7LO3cReyjJPSOZB/QvbTUA6sTMvANKFmnLwK8aSFlQnr8GPUFxtlBy3sAKGA3cqJRqAnxGdsGuvLRCHcARJ+Gv5qbFgwlWNUSkE+CnlCrSIPCm5dupXKciFWtE4R/gR8eb27BkmudH2V8Y2JUd+xOZMOffPNMXrtrGNW0bAXBRrUocTT1FfJLr8qm+EsgqjH53jqHfHZ/S745PWbBoE+//3xyXgwmUnHqEhgThb7STru3YhJWbYt1vVWbGQ8Z+8NOKhBLUFjJyHAu/ameW/RuBBJTYYALF20KpJiJtjQTGrcAidGsj3rQ8bsTIZ+SHUirZjI3cpJSaaMZcmiqlVpss44Bv0cqCRSIzI5OPH/2KN6YN08JSXy1g14ZYbn/xBjb/u4Ol0/6lXqtavPTjY5QpG0Kba1ow4MUbuLfFMJd9NK8TQ892jdiyN45vX9RvJP5v8mIqmhbJTwvWsGjtDto3qckvb9zJiVPpvPzlLPfr4QOBrBef6kXzplUJDwtm4rj7+XL8Ivz9/QCY+tuqQvYuOfV4bXAPWjWoQkRoMNPeu4cxU5acDiA//7GGmpXK8dI93UAptscmMPyL2YVYzBuVPByJeBcIgIw9eowk+BadmPodlOqGlLoWSAd1AnWkZHd5ikXoS0RqoEW+lgOtgPXAAOBZ4BbgALAZ2KWUellE5gNPKqWWm/1fBo4qpd4RkZrA/4BKaJ2f75VSr5p8FdGSp5WUUkcKKlOYI1K1Cejm2YrmwGfzoXyxxOs+zpf5UI7c3tbrPgD+Hvk/r/vwq7T1whT6UkrtBBrkkfS8+eXM3ynH+stOyzuA/CJBB2BSYcHEYrF4hvP2S1kR+QjoDvQo7rJYLBcK521AUUoNKe4yWCwXGufcl7IWi6XkYgOKxWLxGDagWCwWj2EDisVi8Rg2oFgsFo9RLB+2lUREJA7Y5eZu5YF4LxTH+ijZfkqqj+pKqShvFMZVbEA5C0Rkube/TLQ+Sp6f88WHN7BdHovF4jFsQLFYLB7DBpSzY4z1UaJ8+MrP+eLD49gxFIvF4jFsC8VisXgMG1AsFovHsAHFYrF4DBtQLBaLx7ABxQ2cdII6iMhjItJZRCoXtl9JR0QaikhzH/mSwnMVzaYYPO1HRGp7ytb5jg0obqCUUiLSDT0j/zHgE+AGETnnjqPTjdcSGAo8KSKNvOSjrohEi0hpcww9drxERIzNa4AvgI9F5BrlgdeXJj4FA1NF5K2zLqybvn3pz1OcczdCcWEurlCgF1qAbDWQCkxUSmWKSFCBBlz0Yf62FJEmZ2uvIMxN2Av4CkgAygIPiUgLD/u4GlgAvAl8KiLR5nh55NozProArwAfAmHA0KKoROaBQymVip6buLvRjALA00HR/A0TkdJwul5yrgUWG1BcRGmOAnuAd9EXb2+l1H4RuRY46/+7MBfRtehZ/CNypouIx/7xywTAa4FHlFJD0ZOD7wfuF5GGHvLRDOgI9DX2dwFjPBlURGtdl0ULuVUGagMDlVJpIhJ9NraVUhlmsT1ameF1EXnbpGUa/51E5Kx0Ts157wPMASaJyJtZ201ajbOx71OUUvaXz48zH/7FAHXNcl/gD+Ams34xsBHo6AF/tYFlQDWzXhVoZ5YrAG8AlT1Yv++Ad53WewJ/A28BMWdpOxh9Ey4GwtEPrwrAa+gbJ9oD5b8a3fJ5BfgXmIeWTAE9OfkrQKmz9HGDOb+V0YFlCzDSKf09oOpZ+qgHTAMuN8vLss4LWuzubaChN65xT/+KvQAl/Qf0MRfrX+ixkz7mhvvaXASr0S0VT/hqZG7oO4CRwGT0WM0taInVKmdhOys41gNameXm6NbQ3Wa9qfE5CbjkLHzVMkGkNrAKramUlVbRBIFWZ3ms6gEzgJpm/S9gglm+ygSBrkWwG+y07EArJ7zntK0akOQciM/yfDRCP6AmAUFmWziwCbjFrIf58po/m995O+t9URGRQKXUKRHxA6qgBdj7K6XWi8irQEv0/1mkAjWBeKXUxqzBQTd9ZQ0oVgWOoC+iUcB96C7V82gFxUpKqZPA3qLWy/jphn6iIiJTgQnA7+huzvVAQ7TG0WDgIuAfN+vjAMoAT6PF2t4GbgJ+FZFMpdR7SqkDIvKCUqrIavAiUhYYgR4vyRor6QVMFpHv0eftcaWUW3J+ZozsChHZD9QxtpOA+iJSVil1WCm1W0TGAV1FpJxSKrEodTDn4yp063ceOnC1FpGVSqkkEfkaI9erlEouio9iobgjWkn6occttgAtzXoV9Mmub9aD0E/FlzzosyfwJ/Az+q1RE6e0juhuw1VFtC1OyxehhedroJ+A36MDVnV0ELjcLHdAB7baLvoIzGPbZcD/oZUgywB10cFwqAeOV0NzntoBU4C70x2etQAAGfxJREFUgIpO6WWACkW0HQr0RrdItwGlzfbP0a3RG4AngJ84i9aisdkYGA80M+vPGB9PoVvBu4EriuM+OKt6FXcBStqPM0/X5mZ9FDAo6wJCtxiec75Zz8JXZXTTvBW6+3EHMBVoje42rAJ6FdF2NFp83g8ojX6i7wQamPSqaN3n9zDjMkATc5M2cdFHU+A39JO8AbpLGGDS2qJbcq8BgeguSsezPF5l0ONIX5mg0tHUYSBnOebj5OMS9MD7d843tAkkLwG/ABedhX0/9Gxse8yxC3dKewzdhf4w61h54jrz5a/YC1BSfmR/mj+Cnn6vrrnZPze/J4DtQDcP+GuEbg1McdpW3gSwvma9Ws6yuWE/wNzENYAQE7w+NfbrmDxVgYmYFpjZFumG/Qnob1iizc09FvgI02pBd5/2ogOwf1HqkjO/OR+vosd+wo3fycCdWcHMTfsVyNHKQndl+5lzfoPZVgfdgvE/2+vLrF8BbM06107bH0e3JFsCfsV5TxTlZ18bG5RSyoyboJT6AP1kXQwkom+IxejXk3cqpWYWxYfT9wZtgY/Rr2mjROQF4zceSEYHApRSu7PKVoT6pCmlNqNbXHOAw+iB3lT0mEk9pdQe9PjQJqe6J7hQDz+lVBr6bUQ9YDo6AI9EB5r3TdZNwBpgqlIqvSh1MeflMhF5x6yvQHc5EtCBZQU6iP1ryuQS5hOPaHRA7eP83YrSetl/mvpdIyLj0a29Uln1cAensbLLROQ1ERmIPja3ASPN+FWW7/fQrZSn0C27c4vijmjF/ePMaHvWU9XhlPYYEIdp4lLEp1MOf5eixxey3qy0Qt8gX6Ffda7nLLoGTvVxrsdoYCb6VW4N9A3/oVl3uGk/BvNWC7gOfWOPBULNtgbobsg/6JumexHqUBrztgXdWohAB8TXnPJcjx7r+ISzeJKjb+rZpi5Z10DWMQwBOqMDVpG7OcbW1eju7QvoVuI0dJexvbnGbsiR36WWYkn7FXsBSsLP3Mjfo5+uQu7uz36gcRFtV0OPu9Q26/3NhTWcM+MNFdHjD8OBnh6qzwicBo/R3Z1p5iaphVM3x03bndADvBFAV/Qr2v9DD/DWdsrXFTPgWAQflwFfAjcDGzCvzNHdpzdMntYmkBX1vDif45vRg+/X4fTdCvqbo4FFtF8JaJMV7NAD1Dea5XLoLtVYs94H6GyW3QrwJe1X7AUo7h96IHI25s2O03bnC+5R9FPd3f5/A2AteqDzD86MXdxqLuCryfstSZEH4tAtnvXoAd6l6O5GVto4dPfnrC7a/2/vzOOsqK48/j00HRVUVMQNQXEBV8SFRVRkxLUR0KjEDZWIokhQxwXNGEVNJiAYFEVc4m40GIOO+76La8Y1ZqJJdCTBLZsxiTFRzvzxOzWvaBD6VRX9uuk6n099+tV9r+9St+65Z/mdc5E95hrguNQ4rwMmkgOAhewZ/eLzT4F/AUMbtTsP2W5+RwbpZwlzPDLmaP+4Pxp4JwvDAnohdWkisFOUTQduT/2mZ7wXXYqY95Zy1bwDNR28cAzfBeYDW0RZWlVIRN9jkIuvyQsRGfHeBEbG/VUI07JG3B8QjGxfMhgTv6LNrZF6c0KqbG6jFzmv6L4nMC4Y1g2x8NrHAvkxsjd1zFj3mcEsBiLPzY0IJ7NW6jedkAdpuwz1L7JgF8NUHoi5eocMEhaS/t4EjmhU3gmpgpNTczUX2Kg53/llfdW8A80+4AqTSETRDWIRzkwmt9FLVo88CJtV0UZ7pL7cT+jCSN9/CHkkLkCQ6tHA48CaBY1t92jjh8CGqfJXgXsLqL93LLb+cb9fMNrRMeZeQO8c9X8NuWanU9nZZyIDaTuElRmbZ97jc0N6Pht99w0UzJiJ8aLNJw3Nt9S7tgVyFT+IJNf9muu9b66rTSapNrPhwFCkm1+AjJPDkVtwlrv/qtHv23kEg1XRRm9kO6lDhr2n3H2imQ1GC/A2d7/LzLp7eHMyjCPxHvRG3ps/I9vGuUilejCp28wGuvvcLO3E/3cEXqZiQPwgyocjnM597n5V1vqjrg4xjv9AxuMr3f0FM5uFYPzdgTPc/Y4q6kyeUTtXQOJ4hEQe7vLmJL9r7+HBMbMO7v73jGM4Eujr7uMT1HXqu57u/paZrY+Y2LwsCOsWTbXmaM19oV3uBYTBeAaYjXa/PggqfgmpeI4M9adVpt7ANKSbb54qn0mgRsloz0j+D0G2X0fq1PvIC7MnsmmMR8dT5n1m6yMJZCvgDeBbjb7fnwAC5mijG5IUh6Fd/SwkDe0Q329LBZTXZFsD0DP1eWfEFBO1cyDCg6xcbb1LaO9A4LnUfX1qro4Ddm6O97xWV8070OwDhgnIbtGAdNgNo7wdsgNk9X6sSsXVmWYqmyF057lIv94yGMCuGdvpkPq8AfA0cq2ORKpNl/huCLJpZIqEpaIa9kfo3XPivjcKTzi+gLlIqxprI1DXxQgQZ8gzciOwS5a6kQQ6D5gZZesidepKhBB+Btk1Di34HZuDJNJ02U7BjLdtjve8VlfNO7DMB7goQnEUQiI+ScVmMooMXpxUnasG0xiXLHgWlVTOj8XxDinPRZXtrBGMad+474hwDYcgj06SYmEYskesnvPZNcRzuhJhSk5Mjed9YHwB87MjIb0hL884JMHtGkz+HDLYM6jYLTqiuJhz4v4gBCrsg6Suc4CTCnrX6lKf5yBJ+Cy0ib1NAZCAln7VvAPNMkipOfuhOI1OsfjOBDrHC/0G0JCj/jpkR5iG7CNJGHpjpnIRGULqU3WsA0xCGJM9YsE9DvydCiirP5K8MklaqbY6o0DI3eJ+T+BW4Ntxvy0wuIC5OR3hchJ1Zh2EQXkI2KuA+hOczOfAdxp9dzBy7zbZ4N6E9tqnPh+DpK4zU8+x1buGlzj+WndgmQ9QMREfxWJ/LnaobrE4ZgOPEAF4WSY7tRMOiV3pGQReW5yk0qGAdoYhVeanyPW4JhXE6MnIRjAiQ/29YoF1S5VdCZyQansUUiGOSv0mU2wOUgF2QjaGU2NhJ5LKoch7lCupEJLc3kYRyg0oY9zU+G5HpMo1KRByCePoj4zuAxrPVVu8at6BZTKohTOt7UGE/8cL/AoVbEg9lQxfecBkuwBvIQPp5bEjfpNAXVIQ+hFJCT9HasGDyN4wAEldZyFUb9U7IbI3XIiAZLdEvStHOxOpRL4myYDeIMOuTsU4uSdS/XZKlZ2GwGonIYllUAHP61DkFUrue6CYo/PjPlfiIuQZfBF5pR4FDm78DuZ9t1rbVfMOFD6gCjNpAF6Kl38ysFqU74jsAf9e1GTHIpgSn9sDx8aCH03KiJpzPO1j0R8d992R/n8L4QnJ2c4eyMC7MQrR/x7ysvwwGMzNCAa/UfSjyTlakmcfn9dAUuEejZ8/kigmkS3T2uJAa8NQ0GC6bBaSsnLFyiD3/F3BzI8CnkU2oDYrnbgvh9HG7u5mNgABlI5H0sJawGAzW8Xdn0UL/fnk99W2kYoaTjKS/w+wvZn1dvcv3P1KhG0ZiBZQ3vE0oAU/H9jbzDq78CU3oJy2o8xsrZztPIR270PdfQQKrW9ADPgLFHW9D2Jkw+L7pVIkcD7e4vwiV4azeSiBEQjgh5l1c/dbgPO8ykxrUa9HPd80s++Z2fmIcT1sZq+YWT8z+xaal+29CVHVS6F26Jkcj9DCo9z9I5TxrVfOulsv1ZqjFXVR2cnXRPDpl1LfjUOBZCMpKD8nYhZjEDajHkH4z0beiU0R2jIXNiPa6YckhkFIZJ+K7Bod4/4h8sPpk2fXF3mjtkGS3RhkGzob2Wt6Idd0k9tDC7gLUj/HR9mPgOsajXEO+aWGY5Cd7BCEJ3obqW4nx/2DZETypp7R+lRyu5yGknEl8Ue7IpU013y05qvmHShkEJXJ3guJ6Dsgm8b3Ur85Cblti8i2PhglWpqFkKODkBvyZCT6Pk0EmeVsZzVkZL03GWcwxUuQS/JVMhhgl9DeWsGMPyMFcWdh7EuTn19qXtohY/jNSHJsR8QYIXf7KwU9r4tIJQxH+VLuo2KnWSFn/fsiqWd6MN7d0UYyF9ma3qQNuIaX+Ixq3YHCBiID342EKxMZEJ9CInTym+4FtNMTeSAS4+fhseiHxP3qyaKjGPvM0GBax6bK6mN8i8QeFdBe32CKibG6XfpvFfUkzGTV5P9RmP61wRQT5ngEgR6tZhyL+y2y9aTnuxOKis7FSKKurWKe10GG97uR9LNKjOPALONY3q6ad6CQQehlvRD4BymoOUKpvkzk0CigjToEUnoBAcwS0fcQZBPIdZwGC7siG6gkdto9dvGjm+FZ1iMpb2S1TGQxdQ1HtqpLCDQqgulfRcYgv/Rzis8jgukOQqrV/Jij+mD2z5IB4IfUyeNS94NQ9rshSK1KUlFkcjsvr1fNO5C544vfoWYjt2b6bJUtgB3ztgOsEn8TENsl6UWHMn9VDRFfTDv7IC/UySgd5NAoH4wMoWOa4dn2JQ4Yy1HHJsgDNRKlarifSpa6g5DksEHONsYhDM65SN04FUkQTyNJ6EWyJ2DaHBmpT4r7rsEc3yay7AfTvy0Lw1per5p3IONkp13D3wEmxX0dsmvcS8acHF/Rzj7IoHculcOXxiIRexSLyaFSRRv1qc+bIFf3psir8x6y1Rwc3w+hhQeXIVWmZ/Q7ya62YjDE+4gYIDLYslgYhdoZYT+2jPuOsdgPRzE8K5MxLQQVybNnMKpT4v40FMCYGKsLO+Rteblq3oEqJ3odKpJCA0qA3BcBom5G+mwdirR9hOyRvOmYjN2jnQHBrF6nEtMyPl6wdTO20xMZDg9MlfVArtqfxf3RwAIyHqdRw7maFosxOaKjPp7lo2Q40wahUc9GoLgVgoHMZuEo7r0JJGwB/R8QbW2MDPxjEQRgOMq0NoscCOvl9Wo1OBQz2wwFqm0XeTOOQKpHF3TeTJLBvANyH07wKnOYRDtrApPMrEcUbYQ8E52Q9+gs4CAzO8HdLwW+7+7vZ2hnc2Tc/RD4NCl35ehIzuQBYVweRsmgWySlcDm9zWwvM1vR3U9FhsvbzayrKyP9E4h5VnUCYuBwpqJ5/q27f+7uf0N2q9nxPoAWf7c4QD0vrYdiiX6N5v9UdOTFncgONMGVz2b5ymeSl2rN0Zq4WySQ7zGpsjq08J6nEoz3V4Q3yZydHsX+XIQSLyWejtXR4tg27ucgY9+GGdtYD0k6hzQqT7KUbYNijWYhXENyYHqL3QkR2O21eP73UPG2/ScpSSVDvf2RKrNjo/JB8fcCZCS/AhngtyhoPNsj9TM5RXJrZPDNffrh8nzVvANNmNh6ZIy8K+7bo8C4ASir15z42wcZ4nLbGBDQ6vvIc5QctnV3lPdHIu+mOeu/Pj4ngXfHI9Xm1rjfEe2KuSNum2GOtkZRz2sjA+x8dJh84kqfkjDLDHWPACY2elYzYrFPjfdj23heG+YcxxYotUGnuD8KqbSJmr01OU8/XN6vFq/yuETlQ4D+ZnYCwpq86+7PAYnYOxnFVdzs7k+nIPFNpvT/uPsLyA7zBXBiwMfvQfEtVwM3ufvbOYa1Glp8uPuXoV71RAmTuprZxe7+rLtPc/cHsoxnWVOjPv0WBSb2QkmRdkLS4nQzG+ruE939mYxNrQ3sYWb18aySVJDjEQM+Bnglnte7OcexANlnfhTQ/bWAf1I5tPx1d3+iJc5Hi6Fac7SmXsh+8SdgbqPy7mjn6FdAG0MRc5qGbCabI5F6MjL4rkDFZZgnOrkDUtVOSpWtGX8HoR14xaz1N+OcbAcclrofTxzGhVSg+8mfl2UThIsZSKPTAVAg4cQ8cxH1DECpG5I56I0OEnseue6n1fpZt5ar5h2ocuK3CaZydKqsqNQA2yBd/0gkrj+HUgZujDAnFxWxyKngVvZGRtkTU9/1j3YzJ2FqhjlIXOm7Ik/aFwSKF0km7yK7yWvE4VVZ6k8/LwRvvyLaTFJCHIKMvJvkHM+uKIr6QeQ1GppqY/1gLJfTSk/ya/b3o9YdyPAC7IASJk3IWU/nZPeMOm8h8AZRlhj72iHXdK6ddjHtrxa7+PNIXUuC2Vo8riEYx5vIbnVMjOEoZN8agvA5uVIQoITOU1Du167x9/JoawryfuUNitwKedCS9+AUFJ0+ghSOKX7Tt9bPvTVcNe9AxhehP3K1ds8ioSDVZVK8mJsg3f+5kBjSJ7ndRkbvRKqOuqXcd0LguL2pZHhvcd4cKpJJXfT1utR3DQhVmuRqqUv/T4a2DkcI2IHI6H4ZSu7dKb77N6BHzvH0QcGkfwKOSfqLEMrXhGRSj0CG77KcHci1rK4Wb5RdHLn782ihv+cZsCbu/jkK+3e0mP+IXtT1gEPNbBsz64ckk5Wy9NHMVjGzOpchcWczG2NmW7r7l6nftHP3T9z9Rne/391fiv61OFyD+//nZbkVPTczsx5hLL0XRQ6PNbMhyRibOg4zG2Rm/VNFA1Cm+rnu/nWkVl0Yz+omd3/MU2fqVEtmtnP0932Eft3fzPZz0XSkAv3S3f/lMr73c/ffZG2vLVGrZChBn8IiVvolkpmtnHx2eR3mIMTleLRTTUBIyEtR1rUT3P1X1Vr1zWw1FEi2v5nthhIhbQc8YWZ7p/pQNTOsFZnZVkglmOTuD6DdfCywp5ntjuxNDwLHZQCWrQLMN7O14/7XQHcz6wTg7hOAz82scwHj2Ayps+Pc/TXEWH4EjDazg6K9qe7+czOri/uP8rbbVqgIRGFNKNn9qtgFOwD3mtnV7n59/O8LwSsOBEa7+zQzOwXhT95y97uraSNFXyDvQF+k/49x90fN7GlgSqAr76uyzmYlM9sIxTD9FblTV0E4jYQpn4TUg+HIKzIeoZa7EW7WJrZj7n6PmW0IvGRmhyGb0gxgmJn9N/K2rY+ea17qhI49GY1OO/yDmd2L1JujzexJ4GN3X5CWJktqItVa52rOC0Gmf4Yg1OnyXZANZeu47xu/G0N1B6SvSMX1uCkCpj2KkvEkAWcHox24xSbiQYzjV8i4egFKKH09ijuaRRwiTrhxEZMZgZCqTcqIhpjVDOQ9S1zxo6OObZCN4wokRT5C/uz0awPrxeftEZ4pnYBrjeT78sp+tbmzjcMOMBm9TLNTZ95einase+J32wF/cPf/raLunREz+hx5EKYgg2UvlNXrtmjrMOA9d3+q0MEVQKFm3AVc6+7XRtl6CND3MWK8PeP7V1P/dyLwmEuNWFobeyCszwwk3Xzm7mfEd6PRWTaj3f0lM1sVMa7MsUxmNgIB7gx57n4MfInU2t+7+2lZ6y6pEdWao9XiQliD11FiYZAR8BdUYnWqTUGwAVIJ1kX5Xz8EjozvVkUo0h+QM9VBMz2bFdHu3TG5j79dUUqCC1CA5GXI/lTts9oN2b+SBEUjkY1pPLBxlB2J0Le7ZRzD11KfeyBmvnnM0WSEk1kn5v3HpM4/Lq98V6u1oeQhl87+KXBTZMjfCTjV3V+O76sV2/YHHnf3V8zsKZSTdTMz28rd3zCzmWjX7YPE9/kZ22kOWgmpBIOBe9z9H2b2NXf/nZnNQlD0B4AFrojfaun3CCm8CVKrvo0OR+uBMtTv4+7Xm9lnyF1bFZlZT+A0M7sNMZIFSGL8i7t/ambfJ5i+u19sZmPd/ZMM4yhpMdTmVJ40mVk3dAZwe3f/Zc66uqKd9oAoOh3ZFs5DL/VgFHPS4t2PZjYWYX1mBJNM3N9nIozJd3PW3xd5hL5E3pZbo3wKct0fkYXZmtkWaA6uA37i7h+GypQkkn4sykahBE/T8oyjpEWpNbuNc5O7z3P3X2dlJo0CCn+HjK0/iaLLkGh/AzqSYn5rYCZBcxBG47gEV2JmA5HNYW7eyt39RRSzVIe8KwnNQ5igqikYx6XAZe5+qbt/GG39BfV5MHCOmY1DTP7Vr6qrpOzUpiWUPJQk1glcwxruPjfKf4DC6fdDLtc9gb+5+5O16231FJiQb6AzgF5ENojz3P2/CmwjkVSOQ+EUU9G5yW9kqCtJrj3B3T8JDMmCRNIxs32RW3tLdCzJowUNo6QUlQwlB4XHaCY6hNtR7pJ/mtlUtCMO9VYOijKzdeLjiu7+bsJIC6x/B+R5+RglZfpFxnpWQ8emnOEVT1075NlZASWpejjx6hXT+5IaU5tWebJQoubEjtgVOMDdByNR/XZT+sPTqJwT3KrJ3T+I6924L3QHcoUbbIUysGViJlHPn1GA5QFm1ieKzQVO2w04wpTXptxBlyGVEkoGMrNhyBVcB9zo7tdE+WyUlKfB3T+rYRfbJJlZF4Tg7Yxijh5DAYZXoUjyFo1OXh6oZChVUrglpwB3ItdnF+BOD5i+md2Ojo94sXa9bLsUtp+RVM7s2RiY7O53FK2ulbQolQxlKRQo0RXQGTkboSxkN7r7pIg/aUBoz/vd/Y5a9bOkhSkYywKUwPy3JTNpHiptKEug8OA8hBIwreQKZb8f+LqZrRV2hbvRuS3DzKxLtZHJJS0bcvcP3f1jjyM7SmbSPFRKKF9BIX3cDUx396vT3gEzm45g28Pd/WMz2wDAq4j7Kamk5ZFKhvIVFEFqfdz9xHA/9kYGvnmuA57OQ1iTIe7+cS37WlJJLYXaZCxPE+k3wBgz2wsBvFZC7s2XzWxfdx9rZusiw2zJUEoqiVJC+UqKhEzHouTLSW6QN1Cin9PdfVTteldSSS2TSoayFDKzNdz9j6n7XdGBXyOB90tjX0klVaj08iyFEmZiZvUBtZ+BDkifXzKTkkpamEqG0gQKmH0/lNPkrCRWpKSSSlqYSpWniRRMpbO7f1CCpEoqafFUMpSSSiqpMCpVnpJKKqkwKhlKSSWVVBiVDKWkkkoqjEqGUlJJJRVGJUMpqaSSCqOSoZRUUkmF0f8B1qk6Z3JuLIgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "\n",
    "\n",
    "src_ids, src_lengths, trg_ids, _ = next(iter(map_loader))\n",
    "max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS\n",
    "model=attn_seq2seq\n",
    "src_ids_origin=src_ids\n",
    "print(\"src_ids\",src_ids)\n",
    "print(\"length\",src_lengths)\n",
    "print(\"trg_ids\",trg_ids)\n",
    "\n",
    "with torch.no_grad():\n",
    "  src_mask = (src_ids != PAD_INDEX).unsqueeze(-2)\n",
    "  encoder_hiddens, encoder_finals = attn_seq2seq.encode(src_ids.to(device), src_lengths)\n",
    "  prev_y = torch.ones(1, 1).fill_(SOS_INDEX).type_as(src_ids)\n",
    "  trg_mask = torch.ones_like(prev_y)\n",
    "\n",
    "  output = []\n",
    "  attention_scores = []\n",
    "  hidden = None\n",
    "\n",
    "  for i in range(max_len):\n",
    "    with torch.no_grad():\n",
    "      hidden, outputs = attn_seq2seq.decode(encoder_hiddens, encoder_finals, src_mask.to(device),\n",
    "                                     prev_y.to(device), trg_mask.to(device), hidden)\n",
    "      prob = attn_seq2seq.generator(outputs[:, -1])\n",
    "\n",
    "    _, next_word = torch.max(prob, dim=1)\n",
    "    next_word = next_word.data.item()\n",
    "    output.append(next_word)\n",
    "    prev_y = torch.ones(1, 1).fill_(next_word).type_as(src_ids)\n",
    "    attention_scores.append(attn_seq2seq.decoder.alphas.cpu().numpy())\n",
    "\n",
    "  output = np.array(output)\n",
    "\n",
    "  # Cut off everything starting from </s>.\n",
    "  first_eos = np.where(output == EOS_INDEX)[0]\n",
    "  if len(first_eos) > 0:\n",
    "    output = output[:first_eos[0]]\n",
    "\n",
    "# remove <s>\n",
    "src_ids = src_ids[0, 1:]\n",
    "trg_ids = trg_ids[0, 1:]\n",
    "# remove </s> and <pad>\n",
    "src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n",
    "trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n",
    "\n",
    "print(\"Src : \", \" \".join(lookup_words(src_ids, vocab=src_vocab_set)))\n",
    "print(\"Trg : \", \" \".join(lookup_words(trg_ids, vocab=trg_vocab_set)))\n",
    "print(\"Pred: \", \" \".join(lookup_words(output, vocab=trg_vocab_set)))\n",
    "\n",
    "\n",
    "idx = 5\n",
    "src = lookup_words(src_ids, vocab=src_vocab_set) + [\"</s>\"]\n",
    "trg = lookup_words(trg_ids, vocab=trg_vocab_set) + [\"</s>\"]\n",
    "pred = lookup_words(output, vocab=trg_vocab_set).split + [\"xx\"] + [\"</s>\"]\n",
    "\n",
    "\n",
    "\n",
    "vegetables = [\"cucumber\", \"tomato\", \"lettuce\", \"asparagus\",\n",
    "              \"potato\", \"wheat\", \"barley\"]\n",
    "farmers = [\"Farmer Joe\", \"Upland Bros.\", \"Smith Gardening\",\n",
    "           \"Agrifun\", \"Organiculture\", \"BioGoods Ltd.\", \"Cornylee Corp.\"]\n",
    "\n",
    "harvest = np.array([[0.8, 2.4, 2.5, 3.9, 0.0, 4.0, 0.0],\n",
    "                    [2.4, 0.0, 4.0, 1.0, 2.7, 0.0, 0.0],\n",
    "                    [1.1, 2.4, 0.8, 4.3, 1.9, 4.4, 0.0],\n",
    "                    [0.6, 0.0, 0.3, 0.0, 3.1, 0.0, 0.0],\n",
    "                    [0.7, 1.7, 0.6, 2.6, 2.2, 6.2, 0.0],\n",
    "                    [1.3, 1.2, 0.0, 0.0, 0.0, 3.2, 5.1],\n",
    "                    [0.1, 2.0, 0.0, 1.4, 0.0, 1.9, 6.3]])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(harvest)\n",
    "\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange(len(farmers)))\n",
    "ax.set_yticks(np.arange(len(vegetables)))\n",
    "# ... and label them with the respective list entries\n",
    "ax.set_xticklabels(farmers)\n",
    "ax.set_yticklabels(vegetables)\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(len(vegetables)):\n",
    "    for j in range(len(farmers)):\n",
    "        text = ax.text(j, i, harvest[i, j],\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "ax.set_title(\"Harvest of local farmers (in tons/year)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 407,
     "status": "error",
     "timestamp": 1587792658656,
     "user": {
      "displayName": "ByeongJo Kong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64",
      "userId": "10931837966081205326"
     },
     "user_tz": 240
    },
    "id": "78PgWSbcxmCd",
    "outputId": "0593486b-fad8-43de-e8ed-840ea8462d58"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7c589ca550e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"</s>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"</s>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhypotheses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"</s>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def plot_heatmap(src, trg, scores):\n",
    "  fig, ax = plt.subplots()\n",
    "  heatmap = ax.pcolor(scores, cmap='viridis')\n",
    "  \n",
    "  ax.set_xticklabels(trg, minor=False, rotation='vertical')\n",
    "  ax.set_yticklabels(src, minor=False)\n",
    "  \n",
    "  ax.xaxis.tick_top()\n",
    "  ax.set_xticks(np.arange(scores.shape[1]) + 0.5, minor=False)\n",
    "  ax.set_yticks(np.arange(scores.shape[0]) + 0.5, minor=False)\n",
    "  ax.invert_yaxis()\n",
    "  \n",
    "  plt.colorbar(heatmap)\n",
    "  plt.show()\n",
    "\n",
    "\"\"\"\n",
    "def attn_visual(src, trg, scores):\n",
    "  fig, ax = plt.subplots()\n",
    "  attn_map=ax.pcolor(scores,cmap='viridis')\n",
    "  ax.set_xticklabels(trg,minor=False, rotation='vertical')\n",
    "  ax.set_yticklabels(src,minor=False)\n",
    "\n",
    "  ax.xaxis.tick_top()\n",
    "  ax.set_xticklabels(np.arrange(scores.shape[1])+0.5, minor=False)\n",
    "  ax.set_yticklabels(np.arrange(scores.shape[0])+0.5, minor=False)\n",
    "  ax.invert_yaxis()\n",
    "\n",
    "  plt.colorbar(attn_map)\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "idx=5\n",
    "src=valid_data[idx].src+[\"</s>\"]\n",
    "trg=valid_data[idx].trg+[\"</s>\"]\n",
    "pred=hypotheses[idx].split()+[\"</s>\"]\n",
    "pred_attn=alphas[idx][0].T[:,:len(pred)]\n",
    "print(\"src\",src)\n",
    "print(\"ref\",trg)\n",
    "print(\"pred\",pred)\n",
    "attn_visual(src,pred,pred_attn)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 463,
     "status": "error",
     "timestamp": 1587792631605,
     "user": {
      "displayName": "ByeongJo Kong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64",
      "userId": "10931837966081205326"
     },
     "user_tz": 240
    },
    "id": "LiJMHzZ80G62",
    "outputId": "908f49c8-3991-478b-f357-af2e0745f624"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-78070b20a540>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_data' is not defined"
     ]
    }
   ],
   "source": [
    "next(iter(val_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GbOgwJw_CkCW"
   },
   "source": [
    "## **Part 3: Lab writeup**\n",
    "\n",
    "Your lab report should discuss any implementation details that were important to filling out the code above. Then, use the code to set up experiments that answer the following questions:\n",
    "\n",
    "1. In this lab we use greedy search for decoding, that is, always taking the most probable word at current timestep as prediction. Describe an alternative decoding method that might work better than greedy search. You don't have to implement it.\n",
    "\n",
    "2. Pick some samples from dev or test set and visualize their attention maps. Discuss your findings. Hint: compute the attention scores on the input words for each timestep during decoding.\n",
    "\n",
    "3. Compare the performance of seq2seq with and without attention on sentences of different lengths. You can set some length intervals (e.g., 1-10, 11-20, 21-30, 31-40, 41-50) and compare the two models' performance within each length interval. Discuss your findings.\n",
    "\n",
    "4. Try to improve your BLEU score. For example, try stacking more RNN layers, switching cell types, or applying bi-direction to encoder. Describe what you try, even if they don't show improvement. Hints:\n",
    "  * TA's preliminary implemtation of seq2seq with attention model achieves around 16. You don't have to surpass it (although it's pretty simple to do so)--this number is just to give you some sense of what a baseline should get.\n",
    "  * Training on the entire training set takes some time. So tune your hyperparameters on a smaller training set (you can do so by changing `sampling` when creating the data loader)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "qf8Oc9a_ocC_"
   ],
   "machine_shape": "hm",
   "name": "2b_Seq2Seq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
