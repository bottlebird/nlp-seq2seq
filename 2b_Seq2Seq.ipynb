{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2b_Seq2Seq.ipynb","provenance":[],"collapsed_sections":["qf8Oc9a_ocC_"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"FU7xWiY6TyWS","colab_type":"code","colab":{}},"source":["%%bash\n","!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n","rm -rf 6864-hw2b"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uie6jWpIhg_B","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"5AyMA9rK1Rhf","colab_type":"code","colab":{}},"source":["import os\n","os.makedirs(\"6864-hw2b\", exist_ok=True)\n","import sys\n","sys.path.append(\"/content/6864-hw2b\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BL1IfnRdPdsl","colab_type":"code","outputId":"d1333927-5f80-4528-da89-da517630d23a","executionInfo":{"status":"ok","timestamp":1587792685742,"user_tz":240,"elapsed":6196,"user":{"displayName":"ByeongJo Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64","userId":"10931837966081205326"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["!pip install sacrebleu"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Collecting sacrebleu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/27/e9c95f45fc11f9093000d234564823aab762f517458f1aa1ad01ba51d5f2/sacrebleu-1.4.7-py3-none-any.whl (59kB)\n","\r\u001b[K     |█████▌                          | 10kB 22.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.2MB/s \n","\u001b[?25hRequirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n","Collecting mecab-python3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/49/b55a839a77189042960bf96490640c44816073f917d489acbc5d79fa5cc3/mecab_python3-0.996.5-cp36-cp36m-manylinux2010_x86_64.whl (17.1MB)\n","\u001b[K     |████████████████████████████████| 17.1MB 216kB/s \n","\u001b[?25hCollecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n","Installing collected packages: mecab-python3, portalocker, sacrebleu\n","Successfully installed mecab-python3-0.996.5 portalocker-1.7.0 sacrebleu-1.4.7\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5fOArV2r9Piz","colab_type":"text"},"source":["# **Part 3: Sequence-to-Sequence Model**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mA9JfWiK9eoL","colab_type":"text"},"source":["In this lab, you will explore RNN-based sequence-to-sequence (seq2seq) models to perform machine translation (MT). We will use a Vietnamese-English dataset from IWSLT'15. The task is to translate a Vietnamese sentence into English.\n","\n","The lab is divided into two parts. The first part is to implement a vanilla seq2seq architecture without attention. In the second part you will implement your favorite attention mechanism (doesn't have to come from lecture) and add it to your vanilla seq2seq model. We will provide the training and testing scripts (trust me, the decoding/testing is actually the hardest part :P), so you will mainly just have to focus on implementing the models (I say *mainly* because you still might need to modify the testing script, depending on which attention method you use and how you implement it).\n"]},{"cell_type":"markdown","metadata":{"id":"zDJjmvZfHV_l","colab_type":"text"},"source":["## **Section 1: Data Preprocessing**\n","\n","No need to write any code in this section. But you are encouraged to test with this part to understand the data.\n","\n","First, we download the dataset and place it under current directory."]},{"cell_type":"code","metadata":{"id":"02RioHPryvOz","colab_type":"code","outputId":"375d781c-495a-4a0d-a530-85253deb686c","executionInfo":{"status":"ok","timestamp":1587792694860,"user_tz":240,"elapsed":8066,"user":{"displayName":"ByeongJo Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64","userId":"10931837966081205326"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["# Download data\n","!wget -nv -O /content/6864-hw2b/train.en https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en\n","!wget -nv -O /content/6864-hw2b/train.vi https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi\n","!wget -nv -O /content/6864-hw2b/tst2013.en https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en\n","!wget -nv -O /content/6864-hw2b/tst2013.vi https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi\n","!wget -nv -O /content/6864-hw2b/vocab.en https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.en\n","!wget -nv -O /content/6864-hw2b/vocab.vi https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.vi"],"execution_count":10,"outputs":[{"output_type":"stream","text":["2020-04-25 05:31:29 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en [13603614/13603614] -> \"/content/6864-hw2b/train.en\" [1]\n","2020-04-25 05:31:30 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi [18074646/18074646] -> \"/content/6864-hw2b/train.vi\" [1]\n","2020-04-25 05:31:31 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en [132264/132264] -> \"/content/6864-hw2b/tst2013.en\" [1]\n","2020-04-25 05:31:32 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi [183855/183855] -> \"/content/6864-hw2b/tst2013.vi\" [1]\n","2020-04-25 05:31:33 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.en [139741/139741] -> \"/content/6864-hw2b/vocab.en\" [1]\n","2020-04-25 05:31:34 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.vi [46767/46767] -> \"/content/6864-hw2b/vocab.vi\" [1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ogFESHAf-6MY","colab_type":"text"},"source":["Next, we do some simple data preprocessing and show some data statistics."]},{"cell_type":"code","metadata":{"id":"OfkQGqV30hgC","colab_type":"code","outputId":"a5c857f3-4af3-4b53-9bb4-a76b497e6dde","executionInfo":{"status":"ok","timestamp":1587792696633,"user_tz":240,"elapsed":9448,"user":{"displayName":"ByeongJo Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64","userId":"10931837966081205326"}},"colab":{"base_uri":"https://localhost:8080/","height":472}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","def read_sentence_file(filename):\n","  sentences_list = []\n","  with open(filename, \"r\") as f:\n","    for line in f:\n","      sentences_list.append(line.strip().split())\n","  return sentences_list\n","\n","def read_vocab_file(filename):\n","  with open(filename, \"r\") as f:\n","    return [line.strip() for line in f]\n","\n","\n","src_vocab_set = read_vocab_file(os.path.join(\"/content/6864-hw2b\", \"vocab.vi\"))\n","trg_vocab_set = read_vocab_file(os.path.join(\"/content/6864-hw2b\", \"vocab.en\"))\n","\n","train_src_sentences_list = read_sentence_file(os.path.join(\"/content/6864-hw2b\",\n","                                                           \"train.vi\"))\n","train_trg_sentences_list = read_sentence_file(os.path.join(\"/content/6864-hw2b\",\n","                                                           \"train.en\"))\n","assert len(train_src_sentences_list) == len(train_trg_sentences_list)\n","\n","test_src_sentences_list = read_sentence_file(os.path.join(\"/content/6864-hw2b\",\n","                                                          \"tst2013.vi\"))\n","test_trg_sentences_list = read_sentence_file(os.path.join(\"/content/6864-hw2b\",\n","                                                          \"tst2013.en\"))\n","assert len(test_src_sentences_list) == len(test_trg_sentences_list)\n","\n","\n","MAX_SENT_LENGTH = 48\n","MAX_SENT_LENGTH_PLUS_SOS_EOS = 50\n","\n","# We only keep sentences that do not exceed 48 words, so that later when we\n","# add <s> and </s> to a sentence it still won't exceed 50 words.\n","def filter_data(src_sentences_list, trg_sentences_list, max_len):\n","  new_src_sentences_list, new_trg_sentences_list = [], []\n","  for src_sent, trg_sent in zip(src_sentences_list, trg_sentences_list):\n","    if (len(src_sent) <= max_len and len(trg_sent) <= max_len\n","        and len(src_sent) > 0 and len(trg_sent)) > 0:\n","      new_src_sentences_list.append(src_sent)\n","      new_trg_sentences_list.append(trg_sent)\n","  return new_src_sentences_list, new_trg_sentences_list\n","\n","train_src_sentences_list, train_trg_sentences_list = filter_data(\n","    train_src_sentences_list, train_trg_sentences_list, max_len=MAX_SENT_LENGTH)\n","test_src_sentences_list, test_trg_sentences_list = filter_data(\n","    test_src_sentences_list, test_trg_sentences_list, max_len=MAX_SENT_LENGTH)\n","\n","# We take 10% of training data as validation set.\n","num_val = int(len(train_src_sentences_list) * 0.1)\n","val_src_sentences_list = train_src_sentences_list[:num_val]\n","val_trg_sentences_list = train_trg_sentences_list[:num_val]\n","train_src_sentences_list = train_src_sentences_list[num_val:]\n","train_trg_sentences_list = train_trg_sentences_list[num_val:]\n","\n","# Show some data stats\n","print(\"Number of training (src, trg) sentence pairs: %d\" %\n","      len(train_src_sentences_list))\n","print(\"Number of validation (src, trg) sentence pairs: %d\" %\n","      len(val_src_sentences_list))\n","print(\"Number of testing (src, trg) sentence pairs: %d\" %\n","      len(test_src_sentences_list))\n","src_vocab_set = ['<pad>'] + src_vocab_set\n","trg_vocab_set = ['<pad>'] + trg_vocab_set\n","print(\"Size of en vocab set (including '<pad>', '<unk>', '<s>', '</s>'): %d\" %\n","      len(src_vocab_set))\n","print(\"Size of vi vocab set (including '<pad>', '<unk>', '<s>', '</s>'): %d\" %\n","      len(trg_vocab_set))\n","\n","length = [len(sent) for sent in train_src_sentences_list]\n","print('Training sentence avg. length: %d ' % np.mean(length))\n","print('Training sentence length at 95-percentile: %d' %\n","      np.percentile(length, 95))\n","print('Training sentence length distribution '\n","      '(x-axis is length range and y-axis is count):\\n')\n","plt.hist(length, bins=5)\n","plt.show()\n","\n","print('Example Vietnamese input: ' + str(train_src_sentences_list[0]))\n","print('Its target English output: ' + str(train_trg_sentences_list[0]))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Number of training (src, trg) sentence pairs: 108748\n","Number of validation (src, trg) sentence pairs: 12083\n","Number of testing (src, trg) sentence pairs: 1139\n","Size of en vocab set (including '<pad>', '<unk>', '<s>', '</s>'): 7710\n","Size of vi vocab set (including '<pad>', '<unk>', '<s>', '</s>'): 17192\n","Training sentence avg. length: 20 \n","Training sentence length at 95-percentile: 42\n","Training sentence length distribution (x-axis is length range and y-axis is count):\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Example Vietnamese input: ['Adam', 'Sadowsky', 'dàn', 'dựng', '1', 'video', 'âm', 'nhạc', 'hiện', 'tượng', '.']\n","Its target English output: ['Adam', 'Sadowsky', ':', 'How', 'to', 'engineer', 'a', 'viral', 'music', 'video']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"J2x0lhVm_Yxx","colab_type":"text"},"source":["Here we define a class called `MTDataset`. It is built on top of the efficient data loader API provided in PyTorch. See Section 5 for explanation."]},{"cell_type":"code","metadata":{"id":"muwDBzXM5ijT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":232},"outputId":"4fcd45b7-9316-45f5-d788-fb2d0e37c397","executionInfo":{"status":"error","timestamp":1587792722287,"user_tz":240,"elapsed":307,"user":{"displayName":"ByeongJo Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64","userId":"10931837966081205326"}}},"source":["import torch\n","from torch.utils import data\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","assert device == \"cuda\"   # use gpu whenever you can!\n","\n","seed = 42\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","\n","\n","# These IDs are reserved.\n","PAD_INDEX = 0\n","UNK_INDEX = 1\n","SOS_INDEX = 2\n","EOS_INDEX = 3\n","\n","\n","class MTDataset(data.Dataset):\n","  def __init__(self, src_sentences, src_vocabs, trg_sentences, trg_vocabs,\n","               sampling=1.):\n","    self.src_sentences = src_sentences[:int(len(src_sentences) * sampling)]\n","    self.trg_sentences = trg_sentences[:int(len(src_sentences) * sampling)]\n","\n","    self.max_src_seq_length = MAX_SENT_LENGTH_PLUS_SOS_EOS\n","    self.max_trg_seq_length = MAX_SENT_LENGTH_PLUS_SOS_EOS\n","\n","    self.src_vocabs = src_vocabs\n","    self.trg_vocabs = trg_vocabs\n","\n","    self.src_v2id = {v : i for i, v in enumerate(src_vocabs)}\n","    self.src_id2v = {val : key for key, val in self.src_v2id.items()}\n","    self.trg_v2id = {v : i for i, v in enumerate(trg_vocabs)}\n","    self.trg_id2v = {val : key for key, val in self.trg_v2id.items()}\n","\n","  def __len__(self):\n","    return len(self.src_sentences)\n","\n","  def __getitem__(self, index):\n","    src_sent = self.src_sentences[index]\n","    src_len = len(src_sent) + 2   # add <s> and </s> to each sentence\n","    src_id = []\n","    for w in src_sent:\n","      if w not in self.src_vocabs:\n","        w = '<unk>'\n","      src_id.append(self.src_v2id[w])\n","    src_id = ([SOS_INDEX] + src_id + [EOS_INDEX] + [PAD_INDEX] *\n","              (self.max_src_seq_length - src_len))\n","\n","    trg_sent = self.trg_sentences[index]\n","    trg_len = len(trg_sent) + 2\n","    trg_id = []\n","    for w in trg_sent:\n","      if w not in self.trg_vocabs:\n","        w = '<unk>'\n","      trg_id.append(self.trg_v2id[w])\n","    trg_id = ([SOS_INDEX] + trg_id + [EOS_INDEX] + [PAD_INDEX] *\n","              (self.max_trg_seq_length - trg_len))\n","\n","    return torch.tensor(src_id), src_len, torch.tensor(trg_id), trg_len"],"execution_count":14,"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-73876e92dc94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m   \u001b[0;31m# use gpu whenever you can!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"kb5gQEp7oVdi","colab_type":"text"},"source":["## **Section 2: Encoder**\n","\n","Seq2seq consists of an Encoder RNN and a decoder RNN. In a vanilla seq2seq model where there is no attention mechanism between encoder and decoder, the encoder aims to compress the information contained in the entire input sequence into a single vector and pass it to decoder.\n","\n","We start with implementing the encoder, which is just a simple RNN. We use a GRU here, but feel free to try other cell types."]},{"cell_type":"code","metadata":{"id":"dnwVGDVkoPt0","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","\n","class Encoder(nn.Module):\n","  def __init__(self, input_size, hidden_size, dropout=0.):\n","    \"\"\"\n","    Inputs: \n","      - `input_size`: an int representing the RNN input size.\n","      - `hidden_size`: an int representing the RNN hidden size.\n","      - `dropout`: a float representing the dropout rate during training. Note\n","          that for 1-layer RNN this has no effect since dropout only applies to\n","          outputs of intermediate layers.\n","    \"\"\"\n","    super(Encoder, self).__init__()\n","    \n","    # Note: for lab writeup question #4, you can directly change `num_layers`\n","    # and `bidirectional` here to enable deep/bidirectional RNNs. However, you\n","    # will also need to modify some parts in the rest of the code accordingly.\n","    self.rnn = nn.GRU(input_size, hidden_size, num_layers=1, batch_first=True,\n","                      dropout=dropout, bidirectional=False)\n","\n","  def forward(self, inputs, lengths):\n","    \"\"\"\n","    Inputs:\n","      - `inputs`: a 3d-tensor of shape (batch_size, max_seq_length, embed_size)\n","          representing a batch of padded embedded word vectors of source\n","          sentences.\n","      - `lengths`: a 1d-tensor of shape (batch_size,) representing the sequence\n","          lengths of `inputs`.\n","\n","    Returns:\n","      - `outputs`: a 3d-tensor of shape\n","        (batch_size, max_seq_length, hidden_size).\n","      - `finals`: a 3d-tensor of shape (num_layers, batch_size, hidden_size).\n","      Hint: `outputs` and `finals` are both standard GRU outputs. Check:\n","      https://pytorch.org/docs/stable/nn.html#gru\n","    \"\"\"\n","    packed_inputs = pack_padded_sequence(inputs,lengths,batch_first=True,enforce_sorted=False)\n","    outputs, finals = self.rnn(packed_inputs) #output(128,50,256), finals(1,128,256)\n","    outputs, _ = pad_packed_sequence(outputs, batch_first=True, total_length=MAX_SENT_LENGTH_PLUS_SOS_EOS)\n","\n","    return outputs, finals"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Oz3Kc4QKyEP","colab_type":"text"},"source":["## **Section 3: Decoder**\n","\n","Here you will implement a decoder RNN that uses encoder's last hidden state to initialize its initial hidden state."]},{"cell_type":"code","metadata":{"id":"JYT0BlfYUJXj","colab_type":"code","colab":{}},"source":["class Decoder(nn.Module):\n","  \"\"\"An RNN decoder without attention.\"\"\"\n","\n","  def __init__(self, input_size, hidden_size, dropout=0.):\n","    \"\"\"\n","      Inputs:\n","        - `input_size`, `hidden_size`, and `dropout` the same as in Encoder.\n","    \"\"\"\n","    super(Decoder, self).__init__()\n","    self.dropout=nn.Dropout(p=dropout)\n","    self.pre_output=nn.Linear(hidden_size+input_size,hidden_size,bias=False)\n","    self.f_hidden = nn.Linear(hidden_size, hidden_size)\n","    self.rnn = nn.GRU(input_size, hidden_size, num_layers=1, batch_first=True,\n","                      dropout=dropout, bidirectional=False)\n","    \n","  def forward(self, inputs, encoder_finals, hidden=None, max_len=None):\n","    \"\"\"Unroll the decoder one step at a time.\n","\n","    Inputs:\n","      - `inputs`: a 3d-tensor of shape (batch_size, max_seq_length, embed_size)\n","          representing a batch of padded embedded word vectors of target\n","          sentences (for teacher-forcing during training).\n","      - `encoder_finals`: a 3d-tensor of shape\n","          (num_enc_layers, batch_size, hidden_size) representing the final\n","          encoder hidden states used to initialize the initial decoder hidden\n","          states.\n","      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size) representing\n","          the value to be used to initialize the initial decoder hidden states.\n","          If None, then use `encoder_finals`.\n","      - `max_len`: an int representing the maximum decoding length.\n","\n","    Returns:\n","      - `outputs`: a 3d-tensor of shape\n","          (batch_size, max_seq_length, hidden_size) representing the raw\n","          decoder outputs (before converting to a `trg_vocab_size`-dim vector).\n","          We will convert it later in a `Generator` below.\n","      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size)\n","          representing the last decoder hidden state.\n","    \"\"\"\n","    \n","    # The maximum number of steps to unroll the RNN.\n","    if max_len is None:\n","      max_len = inputs.size(1)\n","\n","    # Initialize decoder hidden state.\n","    if hidden is None:\n","      hidden = self.init_hidden(encoder_finals)#encoder_finals)\n","\n","    pre_outputs = []\n","    for i in range(max_len):\n","      prev_embed=inputs[:,i].unsqueeze(1)\n","      context=hidden[-1].unsqueeze(0)\n","      output, hidden = self.rnn(prev_embed,hidden)\n","\n","      pre_output=torch.cat([prev_embed, output], dim=2)\n","      pre_output=self.dropout(pre_output)\n","      pre_output=self.pre_output(pre_output)\n","      pre_outputs.append(pre_output)\n","\n","    outputs=torch.cat(pre_outputs, dim=1)\n","\n","    return hidden, outputs\n","\n","  def init_hidden(self, encoder_finals):\n","    \"\"\"Use encoder final hidden state to initialize decoder's first hidden\n","    state.\"\"\"\n","    ### Your code here!\n","    return torch.tanh(self.f_hidden(encoder_finals))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AH0VdHE2_x1k","colab_type":"text"},"source":["Define the high level encoder-decoder class to wrap up sub-models, including encoder, decoder, generator, and src/trg embeddings."]},{"cell_type":"code","metadata":{"id":"nNBaAYB_oHxG","colab_type":"code","colab":{}},"source":["class EncoderDecoder(nn.Module):\n","  \"\"\"A standard Encoder-Decoder architecture without attention.\n","  \"\"\"\n","  def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n","    \"\"\"\n","    Inputs:\n","      - `encoder`: an `Encoder` object.\n","      - `decoder`: an `Decoder` object.\n","      - `src_embed`: an nn.Embedding object representing the lookup table for\n","          input (source) sentences.\n","      - `trg_embed`: an nn.Embedding object representing the lookup table for\n","          output (target) sentences.\n","      - `generator`: a `Generator` object. Essentially a linear mapping. See\n","          the next code cell.\n","    \"\"\"\n","    super(EncoderDecoder, self).__init__()\n","\n","    self.encoder = encoder\n","    self.decoder = decoder\n","    self.src_embed = src_embed\n","    self.trg_embed = trg_embed\n","    self.generator = generator\n","\n","  def forward(self, src_ids, trg_ids, src_lengths):\n","    \"\"\"Take in and process masked source and target sequences.\n","\n","    Inputs:\n","      `src_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n","        a batch of source sentences of word ids.\n","      `trg_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n","        a batch of target sentences of word ids.\n","      `src_lengths`: a 1d-tensor of shape (batch_size,) representing the\n","        sequence length of `src_ids`.\n","\n","    Returns the decoder outputs, see the above cell.\n","    \"\"\"\n","    encoder_hiddens, encoder_finals = self.encode(src_ids, src_lengths)\n","    del encoder_hiddens   # unused\n","    return self.decode(encoder_finals, trg_ids[:, :-1])\n","\n","  def encode(self, src_ids, src_lengths):\n","    return self.encoder(self.src_embed(src_ids), src_lengths)\n","    \n","  def decode(self, encoder_finals, trg_ids, decoder_hidden=None):\n","    return self.decoder(self.trg_embed(trg_ids), encoder_finals, decoder_hidden)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M06QOTbCALGy","colab_type":"text"},"source":["It simply projects the pre-output layer (x in the forward function below) to obtain the output layer, so that the final dimension is the target vocabulary size."]},{"cell_type":"code","metadata":{"id":"LaHdVcF1KPmd","colab_type":"code","colab":{}},"source":["class Generator(nn.Module):\n","  \"\"\"Define standard linear + softmax generation step.\"\"\"\n","  def __init__(self, hidden_size, vocab_size):\n","    super(Generator, self).__init__()\n","    self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n","\n","  def forward(self, x):\n","    return F.log_softmax(self.proj(x), dim=-1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qf8Oc9a_ocC_","colab_type":"text"},"source":["## **Section 4: Attention-Based Decoder**\n","\n","Now it's time to add some attention to the decoder. You can implement any attention mechanism you want.\n"]},{"cell_type":"code","metadata":{"id":"iZq2NImAoY1C","colab_type":"code","colab":{}},"source":["class AttentionDecoder(nn.Module):\n","  \"\"\"Bahdanau Attention. An attention-based RNN decoder.\"\"\"\n","\n","  def __init__(self, input_size, hidden_size, dropout=0.):\n","    \"\"\"\n","      Inputs:\n","        - `input_size`, `hidden_size`, and `dropout` the same as in Encoder.\n","    \"\"\"\n","    super(AttentionDecoder, self).__init__()\n","    \n","    self.rnn = nn.GRU(input_size + hidden_size, hidden_size, batch_first=True,\n","                      dropout=dropout)\n","    ##attention\n","    self.alphas=None\n","    self.query=nn.Linear(hidden_size, hidden_size, bias=False)\n","    self.energy=nn.Linear(hidden_size, 1, bias=False)\n","    self.key=nn.Linear(hidden_size,hidden_size, bias=False)\n","\n","    self.dropout=nn.Dropout(p=dropout)\n","    self.pre_output=nn.Linear(hidden_size+hidden_size+input_size,hidden_size,bias=False)\n","    self.f_hidden = nn.Linear(hidden_size, hidden_size)\n","    \n","\n","  def forward(self, inputs, encoder_hiddens, encoder_finals,\n","              src_mask, trg_mask, hidden=None, max_len=None):\n","    # The maximum number of steps to unroll the RNN.\n","    if max_len is None:\n","      max_len = trg_mask.size(-1)\n","\n","    # Initialize decoder hidden state.\n","    if hidden is None:\n","      hidden = self.init_hidden(encoder_finals)\n","\n","    proj_key=self.key(encoder_hiddens)\n","    pre_outputs = []\n","    decoder_states = []\n","\n","    #for loop step forward\n","    for i in range(max_len):\n","      prev_embed=inputs[:,i].unsqueeze(1)\n","      #Attention function\n","      query=hidden[-1].unsqueeze(1)\n","      context, attn_probs = self.attention(query, proj_key, encoder_hiddens, src_mask)\n","      \n","      rnn_input=torch.cat([prev_embed,context],dim=2)\n","      output, hidden = self.rnn(rnn_input,hidden)\n","\n","      pre_output=torch.cat([prev_embed, output, context], dim=2)\n","      pre_output=self.dropout(pre_output)\n","      pre_output=self.pre_output(pre_output)\n","      pre_outputs.append(pre_output)\n","\n","    pre_outputs=torch.cat(pre_outputs, dim=1)\n","    return hidden, pre_outputs\n","\n","  def init_hidden(self, encoder_finals):\n","    \"\"\"Use encoder final hidden state to initialize decoder's first hidden\n","    state.\"\"\"\n","    return torch.tanh(self.f_hidden(encoder_finals))\n","\n","  def attention(self, query, proj_key, encoder_hiddens, mask):\n","    query=self.query(query)\n","\n","    scores=self.energy(torch.tanh(query+proj_key))\n","    scores=scores.squeeze(2).unsqueeze(1)\n","    scores.data.masked_fill_(mask == 0, -float('inf'))\n","    \n","    alphas=F.softmax(scores,dim=-1)\n","    self.alphas=alphas\n","    \n","    context=torch.bmm(alphas, encoder_hiddens)\n","\n","    return context, alphas"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DTUXxJWPPQ9W","colab_type":"text"},"source":["Similarly, we use a `EncoderAttentionDecoder` class to wrap up all encoder, decoder, src/trg embeddings, and generator. You can take the `EncoderDecoder` class as a reference."]},{"cell_type":"code","metadata":{"id":"mghIa6XzubZL","colab_type":"code","colab":{}},"source":["class EncoderAttentionDecoder(nn.Module):\n","  \"\"\"A Encoder-Decoder architecture with attention.\n","  \"\"\"\n","  def __init__(self, encoder, decoder, src_embed , trg_embed, generator):\n","    \"\"\"\n","    Inputs:\n","      - `encoder`: an `Encoder` object.\n","      - `decoder`: an `AttentionDecoder` object.\n","      - `src_embed`: an nn.Embedding object representing the lookup table for\n","          input (source) sentences.\n","      - `trg_embed`: an nn.Embedding object representing the lookup table for\n","          output (target) sentences.\n","      - `generator`: a `Generator` object. Essentially a linear mapping. See\n","          the next code cell.\n","    \"\"\"\n","    super(EncoderAttentionDecoder, self).__init__()\n","\n","    self.encoder = encoder\n","    self.decoder = decoder\n","    self.src_embed = src_embed\n","    self.trg_embed = trg_embed\n","    self.generator = generator\n","\n","  def forward(self, src_ids, trg_ids, src_lengths):\n","    \"\"\"Take in and process masked source and target sequences.\n","\n","    Inputs:\n","      `src_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n","        a batch of source sentences of word ids.\n","      `trg_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n","        a batch of target sentences of word ids.\n","      `src_lengths`: a 1d-tensor of shape (batch_size,) representing the\n","        sequence length of `src_ids`.\n","\n","    Returns the decoder outputs, see the above cell.\n","    \"\"\"\n","    ### Your code here!\n","    # You can refer to `EncoderDecoder` and extend from it.\n","    encoder_hiddens, encoder_finals = self.encode(src_ids, src_lengths)\n","    src_mask = (src_ids != PAD_INDEX).unsqueeze(-2)\n","    trg_mask = (trg_ids[:, 1:] != PAD_INDEX).unsqueeze(-2)\n","    return self.decode(encoder_hiddens, encoder_finals,\n","                       src_mask, trg_ids[:, :-1], trg_mask)\n","\n","  def encode(self, src_ids, src_lengths):\n","    return self.encoder(self.src_embed(src_ids), src_lengths)\n","\n","  def decode(self, encoder_hiddens, encoder_finals, src_mask, \n","             trg_ids, trg_mask, hidden=None):\n","    return self.decoder(self.trg_embed(trg_ids), encoder_hiddens,\n","                        encoder_finals, src_mask, trg_mask, hidden)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9VIpNlKtK8l_","colab_type":"text"},"source":["## **Section 5: Training and Testing**\n","\n","We provide training and testing scripts here. You might need to adapt them to fit your model implementation."]},{"cell_type":"markdown","metadata":{"id":"I38IFq48BKa5","colab_type":"text"},"source":["Apply the dataloader to the MT dataset. Dataloader provides a convenient way to iterate through the whole dataset."]},{"cell_type":"code","metadata":{"id":"cJrXO7nCjzBP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":232},"outputId":"981a1975-d106-4d12-aaeb-26142c0976da","executionInfo":{"status":"error","timestamp":1587792699260,"user_tz":240,"elapsed":474,"user":{"displayName":"ByeongJo Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64","userId":"10931837966081205326"}}},"source":["batch_size = 128\n","\n","# You can try on a smaller training set by setting a smaller `sampling`.\n","train_set = MTDataset(train_src_sentences_list, src_vocab_set,\n","                      train_trg_sentences_list, trg_vocab_set, sampling=1.)\n","train_data_loader = data.DataLoader(train_set, batch_size=batch_size,\n","                                    num_workers=8, shuffle=True)\n","\n","val_set = MTDataset(val_src_sentences_list, src_vocab_set,\n","                    val_trg_sentences_list, trg_vocab_set, sampling=1.)\n","val_data_loader = data.DataLoader(val_set, batch_size=batch_size, num_workers=8,\n","                                  shuffle=False)"],"execution_count":13,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-fb407930265b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# You can try on a smaller training set by setting a smaller `sampling`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m train_set = MTDataset(train_src_sentences_list, src_vocab_set,\n\u001b[0m\u001b[1;32m      5\u001b[0m                       train_trg_sentences_list, trg_vocab_set, sampling=1.)\n\u001b[1;32m      6\u001b[0m train_data_loader = data.DataLoader(train_set, batch_size=batch_size,\n","\u001b[0;31mNameError\u001b[0m: name 'MTDataset' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"bWaiu7wNBX7x","colab_type":"text"},"source":["The main functions for training, here we use perplexity to evaluate the performance of the model. Although we provide the training scripts here, we strongly encoureage you to go through and understand the procedure."]},{"cell_type":"code","metadata":{"id":"AXGa-L1qp13q","colab_type":"code","colab":{}},"source":["import math\n","\n","\n","class SimpleLossCompute:\n","  \"\"\"A simple loss compute and train function.\"\"\"\n","\n","  def __init__(self, generator, criterion, opt=None):\n","    self.generator = generator\n","    self.criterion = criterion\n","    self.opt = opt\n","\n","  def __call__(self, x, y, norm):\n","    x = self.generator(x)\n","    loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n","                          y.contiguous().view(-1))\n","    loss = loss / norm\n","\n","    if self.opt is not None:  # training mode\n","      loss.backward()          \n","      self.opt.step()\n","      self.opt.zero_grad()\n","\n","    return loss.data.item() * norm\n","\n","\n","def run_epoch(data_loader, model, loss_compute, print_every):\n","  \"\"\"Standard Training and Logging Function\"\"\"\n","\n","  total_tokens = 0\n","  total_loss = 0\n","\n","  for i, (src_ids_BxT, src_lengths_B, trg_ids_BxL, trg_lengths_B) in enumerate(data_loader):\n","    # We define some notations here to help you understand the loaded tensor\n","    # shapes:\n","    #   `B`: batch size\n","    #   `T`: max sequence length of source sentences\n","    #   `L`: max sequence length of target sentences; due to our preprocessing\n","    #        in the beginning, `L` == `T` == 50\n","    # An example of `src_ids_BxT` (when B = 2):\n","    #   [[2, 4, 6, 7, ..., 4, 3, 0, 0, 0],\n","    #    [2, 8, 6, 5, ..., 9, 5, 4, 3, 0]]\n","    # The corresponding `src_lengths_B` would be [47, 49].\n","    # Note that SOS_INDEX == 2, EOS_INDEX == 3, and PAD_INDEX = 0.\n","\n","    src_ids_BxT = src_ids_BxT.to(device)\n","    src_lengths_B = src_lengths_B.to(device)\n","    trg_ids_BxL = trg_ids_BxL.to(device)\n","    del trg_lengths_B   # unused\n","\n","    _, output = model(src_ids_BxT, trg_ids_BxL, src_lengths_B)\n","\n","    loss = loss_compute(x=output, y=trg_ids_BxL[:, 1:],\n","                        norm=src_ids_BxT.size(0))\n","    total_loss += loss\n","    total_tokens += (trg_ids_BxL[:, 1:] != PAD_INDEX).data.sum().item()\n","\n","    if model.training and i % print_every == 0:\n","      print(\"Epoch Step: %d Loss: %f\" % (i, loss / src_ids_BxT.size(0)))\n","\n","  return math.exp(total_loss / float(total_tokens))\n","\n","\n","def train(model, num_epochs, learning_rate, print_every):\n","  # Set `ignore_index` as PAD_INDEX so that pad tokens won't be included when\n","  # computing the loss.\n","  criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n","  optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","  # Keep track of dev ppl for each epoch.\n","  dev_ppls = []\n","\n","  for epoch in range(num_epochs):\n","    print(\"Epoch\", epoch)\n","\n","    model.train()\n","    train_ppl = run_epoch(data_loader=train_data_loader, model=model,\n","                          loss_compute=SimpleLossCompute(model.generator,\n","                                                         criterion, optim),\n","                          print_every=print_every)\n","        \n","    model.eval()\n","    with torch.no_grad():      \n","      dev_ppl = run_epoch(data_loader=val_data_loader, model=model,\n","                          loss_compute=SimpleLossCompute(model.generator,\n","                                                         criterion, None),\n","                          print_every=print_every)\n","      print(\"Validation perplexity: %f\" % dev_ppl)\n","      dev_ppls.append(dev_ppl)\n","        \n","  return dev_ppls"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1A8VvkcICT60","colab_type":"text"},"source":["The main function to perform training. First let's train the vanilla seq2seq model."]},{"cell_type":"code","metadata":{"id":"pZ0t1hXAIHtO","colab_type":"code","outputId":"8c619086-0349-4b9d-a67a-c81ae3fe8eec","executionInfo":{"status":"ok","timestamp":1587787858894,"user_tz":240,"elapsed":739112,"user":{"displayName":"ByeongJo Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64","userId":"10931837966081205326"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Hyperparameters for contructing the encoder-decoder model.\n","\n","embed_size = 256   # Each word will be represented as a `embed_size`-dim vector.\n","hidden_size = 256  # RNN hidden size.\n","dropout = 0.2\n","\n","pure_seq2seq = EncoderDecoder(\n","  encoder=Encoder(embed_size, hidden_size, dropout=dropout),\n","  decoder=Decoder(embed_size, hidden_size, dropout=dropout),\n","  src_embed=nn.Embedding(len(src_vocab_set), embed_size),\n","  trg_embed=nn.Embedding(len(trg_vocab_set), embed_size),\n","  generator=Generator(hidden_size, len(trg_vocab_set))).to(device)\n","\n","# Start training. The returned `dev_ppls` is a list of dev perplexity for each\n","# epoch.\n","pure_dev_ppls = train(pure_seq2seq, num_epochs=10, learning_rate=1e-3,\n","                      print_every=100)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch Step: 0 Loss: 180.800476\n","Epoch Step: 100 Loss: 94.416428\n","Epoch Step: 200 Loss: 93.681999\n","Epoch Step: 300 Loss: 95.686226\n","Epoch Step: 400 Loss: 86.516792\n","Epoch Step: 500 Loss: 91.004654\n","Epoch Step: 600 Loss: 79.095680\n","Epoch Step: 700 Loss: 78.601418\n","Epoch Step: 800 Loss: 77.361351\n","Validation perplexity: 71.051127\n","Epoch 1\n","Epoch Step: 0 Loss: 72.375206\n","Epoch Step: 100 Loss: 67.722382\n","Epoch Step: 200 Loss: 78.160042\n","Epoch Step: 300 Loss: 76.917755\n","Epoch Step: 400 Loss: 78.162933\n","Epoch Step: 500 Loss: 76.915680\n","Epoch Step: 600 Loss: 70.338127\n","Epoch Step: 700 Loss: 69.189644\n","Epoch Step: 800 Loss: 66.426300\n","Validation perplexity: 52.511022\n","Epoch 2\n","Epoch Step: 0 Loss: 68.302696\n","Epoch Step: 100 Loss: 65.257988\n","Epoch Step: 200 Loss: 72.143867\n","Epoch Step: 300 Loss: 71.210831\n","Epoch Step: 400 Loss: 68.574921\n","Epoch Step: 500 Loss: 69.582764\n","Epoch Step: 600 Loss: 71.969360\n","Epoch Step: 700 Loss: 65.980110\n","Epoch Step: 800 Loss: 65.953796\n","Validation perplexity: 45.258742\n","Epoch 3\n","Epoch Step: 0 Loss: 63.800259\n","Epoch Step: 100 Loss: 65.001556\n","Epoch Step: 200 Loss: 62.651897\n","Epoch Step: 300 Loss: 66.703697\n","Epoch Step: 400 Loss: 63.178455\n","Epoch Step: 500 Loss: 59.345619\n","Epoch Step: 600 Loss: 64.613022\n","Epoch Step: 700 Loss: 61.213196\n","Epoch Step: 800 Loss: 63.793270\n","Validation perplexity: 40.699008\n","Epoch 4\n","Epoch Step: 0 Loss: 57.413181\n","Epoch Step: 100 Loss: 60.674175\n","Epoch Step: 200 Loss: 60.196899\n","Epoch Step: 300 Loss: 60.575245\n","Epoch Step: 400 Loss: 64.033066\n","Epoch Step: 500 Loss: 51.643044\n","Epoch Step: 600 Loss: 61.856510\n","Epoch Step: 700 Loss: 65.049263\n","Epoch Step: 800 Loss: 57.675377\n","Validation perplexity: 38.447554\n","Epoch 5\n","Epoch Step: 0 Loss: 59.466991\n","Epoch Step: 100 Loss: 56.243259\n","Epoch Step: 200 Loss: 61.538574\n","Epoch Step: 300 Loss: 58.687584\n","Epoch Step: 400 Loss: 59.697945\n","Epoch Step: 500 Loss: 59.319359\n","Epoch Step: 600 Loss: 60.295422\n","Epoch Step: 700 Loss: 59.530258\n","Epoch Step: 800 Loss: 56.558701\n","Validation perplexity: 36.709199\n","Epoch 6\n","Epoch Step: 0 Loss: 50.550560\n","Epoch Step: 100 Loss: 50.035679\n","Epoch Step: 200 Loss: 49.773224\n","Epoch Step: 300 Loss: 52.014065\n","Epoch Step: 400 Loss: 53.050991\n","Epoch Step: 500 Loss: 57.095772\n","Epoch Step: 600 Loss: 55.107407\n","Epoch Step: 700 Loss: 57.798492\n","Epoch Step: 800 Loss: 56.247143\n","Validation perplexity: 35.972170\n","Epoch 7\n","Epoch Step: 0 Loss: 52.339329\n","Epoch Step: 100 Loss: 51.422825\n","Epoch Step: 200 Loss: 58.375050\n","Epoch Step: 300 Loss: 50.992645\n","Epoch Step: 400 Loss: 53.476711\n","Epoch Step: 500 Loss: 53.108189\n","Epoch Step: 600 Loss: 55.163002\n","Epoch Step: 700 Loss: 57.035294\n","Epoch Step: 800 Loss: 52.549847\n","Validation perplexity: 35.842337\n","Epoch 8\n","Epoch Step: 0 Loss: 51.671635\n","Epoch Step: 100 Loss: 54.254322\n","Epoch Step: 200 Loss: 48.571022\n","Epoch Step: 300 Loss: 51.391994\n","Epoch Step: 400 Loss: 50.869495\n","Epoch Step: 500 Loss: 55.859024\n","Epoch Step: 600 Loss: 55.720406\n","Epoch Step: 700 Loss: 57.278484\n","Epoch Step: 800 Loss: 50.723438\n","Validation perplexity: 35.645660\n","Epoch 9\n","Epoch Step: 0 Loss: 46.211365\n","Epoch Step: 100 Loss: 48.801414\n","Epoch Step: 200 Loss: 46.954803\n","Epoch Step: 300 Loss: 57.312435\n","Epoch Step: 400 Loss: 54.114754\n","Epoch Step: 500 Loss: 50.375950\n","Epoch Step: 600 Loss: 50.307476\n","Epoch Step: 700 Loss: 52.091942\n","Epoch Step: 800 Loss: 54.285233\n","Validation perplexity: 35.532861\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fRsfDg0wCa7U","colab_type":"text"},"source":["Plot the perplexity graph."]},{"cell_type":"code","metadata":{"id":"CTApnlT53YvT","colab_type":"code","outputId":"bd799dd9-cd8e-45ed-918a-40abaa48c312","executionInfo":{"status":"ok","timestamp":1587787889908,"user_tz":240,"elapsed":424,"user":{"displayName":"ByeongJo Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64","userId":"10931837966081205326"}},"colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["def plot_perplexity(perplexities):\n","  \"\"\"plot perplexities\"\"\"\n","  plt.title(\"Perplexity per Epoch\")\n","  plt.xlabel(\"Epoch\")\n","  plt.ylabel(\"Perplexity\")\n","  plt.plot(perplexities)\n","\n","plot_perplexity(pure_dev_ppls)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"PjhKXDyvIk4l","colab_type":"text"},"source":["Now, let's train the seq2seq model with attention."]},{"cell_type":"code","metadata":{"id":"onQxDU-aGa0t","colab_type":"code","outputId":"07688f96-f82f-4092-aa85-4f02d08c3274","executionInfo":{"status":"ok","timestamp":1587791483068,"user_tz":240,"elapsed":1072654,"user":{"displayName":"ByeongJo Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64","userId":"10931837966081205326"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["attn_seq2seq = EncoderAttentionDecoder(\n","    encoder=Encoder(embed_size, hidden_size, dropout=dropout),\n","    decoder=AttentionDecoder(embed_size, hidden_size, dropout=dropout),\n","    src_embed=nn.Embedding(len(src_vocab_set), embed_size),\n","    trg_embed=nn.Embedding(len(trg_vocab_set), embed_size),\n","    generator=Generator(hidden_size, len(trg_vocab_set))).to(device)\n","\n","attn_dev_ppls = train(attn_seq2seq, num_epochs=10, learning_rate=1e-3,\n","                      print_every=100)\n","\n","plot_perplexity(attn_dev_ppls)"],"execution_count":52,"outputs":[{"output_type":"stream","text":["Epoch 0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch Step: 0 Loss: 173.961838\n","Epoch Step: 100 Loss: 86.523758\n","Epoch Step: 200 Loss: 84.875389\n","Epoch Step: 300 Loss: 86.142601\n","Epoch Step: 400 Loss: 79.161850\n","Epoch Step: 500 Loss: 75.209167\n","Epoch Step: 600 Loss: 68.289726\n","Epoch Step: 700 Loss: 69.921318\n","Epoch Step: 800 Loss: 67.139748\n","Validation perplexity: 33.190483\n","Epoch 1\n","Epoch Step: 0 Loss: 61.064266\n","Epoch Step: 100 Loss: 56.369087\n","Epoch Step: 200 Loss: 56.496857\n","Epoch Step: 300 Loss: 54.140171\n","Epoch Step: 400 Loss: 64.135452\n","Epoch Step: 500 Loss: 54.523895\n","Epoch Step: 600 Loss: 59.223339\n","Epoch Step: 700 Loss: 52.484112\n","Epoch Step: 800 Loss: 50.312088\n","Validation perplexity: 21.409765\n","Epoch 2\n","Epoch Step: 0 Loss: 49.529953\n","Epoch Step: 100 Loss: 49.145195\n","Epoch Step: 200 Loss: 51.252449\n","Epoch Step: 300 Loss: 50.882988\n","Epoch Step: 400 Loss: 47.252274\n","Epoch Step: 500 Loss: 55.430546\n","Epoch Step: 600 Loss: 49.439045\n","Epoch Step: 700 Loss: 45.764759\n","Epoch Step: 800 Loss: 46.661873\n","Validation perplexity: 18.156633\n","Epoch 3\n","Epoch Step: 0 Loss: 40.991589\n","Epoch Step: 100 Loss: 44.170502\n","Epoch Step: 200 Loss: 42.697418\n","Epoch Step: 300 Loss: 41.094837\n","Epoch Step: 400 Loss: 41.308578\n","Epoch Step: 500 Loss: 44.647938\n","Epoch Step: 600 Loss: 41.350948\n","Epoch Step: 700 Loss: 46.365185\n","Epoch Step: 800 Loss: 45.636353\n","Validation perplexity: 16.800077\n","Epoch 4\n","Epoch Step: 0 Loss: 39.163403\n","Epoch Step: 100 Loss: 40.560047\n","Epoch Step: 200 Loss: 38.331028\n","Epoch Step: 300 Loss: 41.026253\n","Epoch Step: 400 Loss: 40.085930\n","Epoch Step: 500 Loss: 40.180458\n","Epoch Step: 600 Loss: 45.569820\n","Epoch Step: 700 Loss: 38.299404\n","Epoch Step: 800 Loss: 46.100609\n","Validation perplexity: 16.340441\n","Epoch 5\n","Epoch Step: 0 Loss: 43.098671\n","Epoch Step: 100 Loss: 39.739197\n","Epoch Step: 200 Loss: 35.147041\n","Epoch Step: 300 Loss: 38.715248\n","Epoch Step: 400 Loss: 31.858690\n","Epoch Step: 500 Loss: 39.206696\n","Epoch Step: 600 Loss: 39.512852\n","Epoch Step: 700 Loss: 44.780029\n","Epoch Step: 800 Loss: 39.000629\n","Validation perplexity: 15.972428\n","Epoch 6\n","Epoch Step: 0 Loss: 32.748123\n","Epoch Step: 100 Loss: 32.134491\n","Epoch Step: 200 Loss: 33.444447\n","Epoch Step: 300 Loss: 38.044365\n","Epoch Step: 400 Loss: 33.150269\n","Epoch Step: 500 Loss: 32.323727\n","Epoch Step: 600 Loss: 40.275795\n","Epoch Step: 700 Loss: 40.679310\n","Epoch Step: 800 Loss: 39.806385\n","Validation perplexity: 16.071157\n","Epoch 7\n","Epoch Step: 0 Loss: 31.731138\n","Epoch Step: 100 Loss: 33.664185\n","Epoch Step: 200 Loss: 38.695042\n","Epoch Step: 300 Loss: 35.774673\n","Epoch Step: 400 Loss: 39.228970\n","Epoch Step: 500 Loss: 33.066689\n","Epoch Step: 600 Loss: 34.836521\n","Epoch Step: 700 Loss: 34.423698\n","Epoch Step: 800 Loss: 38.685940\n","Validation perplexity: 16.622203\n","Epoch 8\n","Epoch Step: 0 Loss: 33.902027\n","Epoch Step: 100 Loss: 34.106220\n","Epoch Step: 200 Loss: 31.810324\n","Epoch Step: 300 Loss: 35.454079\n","Epoch Step: 400 Loss: 30.807549\n","Epoch Step: 500 Loss: 36.093288\n","Epoch Step: 600 Loss: 32.337551\n","Epoch Step: 700 Loss: 32.712444\n","Epoch Step: 800 Loss: 34.662357\n","Validation perplexity: 16.812770\n","Epoch 9\n","Epoch Step: 0 Loss: 31.694666\n","Epoch Step: 100 Loss: 33.604237\n","Epoch Step: 200 Loss: 34.413559\n","Epoch Step: 300 Loss: 29.905518\n","Epoch Step: 400 Loss: 34.030510\n","Epoch Step: 500 Loss: 28.920845\n","Epoch Step: 600 Loss: 31.906029\n","Epoch Step: 700 Loss: 35.249615\n","Epoch Step: 800 Loss: 30.963758\n","Validation perplexity: 17.567189\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"yVXcevCLCa2B","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-nv4S47JjCJ","colab_type":"code","colab":{}},"source":["torch.save({'state_dict': attn_seq2seq.state_dict()}, 'drive/My Drive/Colab Notebooks/NLP/2.Seq2Seq/attn_checkpoint.pt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xn5BokU9CetS","colab_type":"code","colab":{}},"source":["path='drive/My Drive/Colab Notebooks/NLP/2.Seq2Seq/pure_checkpoint.pt'\n","\n","pure_seq2seq.load_state_dict(torch.load(path), strict=False)\n","pure_seq2seq.eval()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VMpL-_MwJOws","colab_type":"text"},"source":["This is the function used to decode the model output. For simplicity, we use greedy search here."]},{"cell_type":"code","metadata":{"id":"M1HTqYwy6-yL","colab_type":"code","colab":{}},"source":["def greedy_decode(model, src_ids, src_lengths, max_len):\n","  \"\"\"Greedily decode a sentence for EncoderDecoder.\"\"\"\n","\n","  with torch.no_grad():\n","    _, encoder_finals = model.encode(src_ids, src_lengths)\n","    prev_y = torch.ones(1, 1).fill_(SOS_INDEX).type_as(src_ids)\n","\n","  output = []\n","  hidden = None\n","\n","  for i in range(max_len):\n","    with torch.no_grad():\n","      hidden, outputs = model.decode(encoder_finals, prev_y, hidden)\n","      prob = model.generator(outputs[:, -1])\n","\n","    _, next_word = torch.max(prob, dim=1)\n","    next_word = next_word.data.item()\n","    output.append(next_word)\n","    prev_y = torch.ones(1, 1).type_as(src_ids).fill_(next_word)\n","\n","  output = np.array(output)\n","\n","  # Cut off everything starting from </s>.\n","  first_eos = np.where(output == EOS_INDEX)[0]\n","  if len(first_eos) > 0:\n","    output = output[:first_eos[0]]\n","  return output\n","\n","\n","def greedy_decode_attention(model, src_ids, src_lengths, max_len):\n","  \"\"\"Greedily decode a sentence for EncoderAttentionDecoder.\"\"\"\n","\n","  with torch.no_grad():\n","    src_mask = (src_ids != PAD_INDEX).unsqueeze(-2)\n","    encoder_hiddens, encoder_finals = model.encode(src_ids, src_lengths)\n","    prev_y = torch.ones(1, 1).fill_(SOS_INDEX).type_as(src_ids)\n","    trg_mask = torch.ones_like(prev_y)\n","\n","  output = []\n","  attention_scores = []\n","  hidden = None\n","\n","  for i in range(max_len):\n","    with torch.no_grad():\n","      hidden, outputs = model.decode(encoder_hiddens, encoder_finals, src_mask,\n","                                     prev_y, trg_mask, hidden)\n","      prob = model.generator(outputs[:, -1])\n","\n","    _, next_word = torch.max(prob, dim=1)\n","    next_word = next_word.data.item()\n","    output.append(next_word)\n","    prev_y = torch.ones(1, 1).fill_(next_word).type_as(src_ids)\n","    attention_scores.append(model.decoder.alphas.cpu().numpy())\n","\n","  output = np.array(output)\n","\n","  # Cut off everything starting from </s>.\n","  first_eos = np.where(output == EOS_INDEX)[0]\n","  if len(first_eos) > 0:\n","    output = output[:first_eos[0]]\n","  return output, np.concatenate(attention_scores, axis=1)\n","  \n","\n","def lookup_words(x, vocab):\n","  return [vocab[i] for i in x]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d_5go3VxJZKh","colab_type":"text"},"source":["Print the top 3 examples from the data loader by applying the greedy decoder."]},{"cell_type":"code","metadata":{"id":"cc3m4optFrb3","colab_type":"code","colab":{}},"source":["def print_examples(model, data_loader, n=3,\n","                   max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS, \n","                   src_vocab_set=src_vocab_set, trg_vocab_set=trg_vocab_set):\n","  \"\"\"Prints `n` examples. Assumes batch size of 1.\"\"\"\n","\n","  model.eval()\n","\n","  for i, (src_ids, src_lengths, trg_ids, _) in enumerate(data_loader):\n","    if isinstance(model, EncoderDecoder):\n","      result = greedy_decode(model, src_ids.to(device), src_lengths.to(device),\n","                             max_len=max_len)\n","    elif isinstance(model, EncoderAttentionDecoder):\n","      result, _ = greedy_decode_attention(model, src_ids.to(device),\n","                                          src_lengths.to(device),\n","                                          max_len=max_len)\n","    else:\n","      raise NotImplementedError(\"Unknown model type.\")\n","\n","    # remove <s>\n","    src_ids = src_ids[0, 1:]\n","    trg_ids = trg_ids[0, 1:]\n","    # remove </s> and <pad>\n","    src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n","    trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n","\n","    print(\"Example #%d\" % (i + 1))\n","    print(\"Src : \", \" \".join(lookup_words(src_ids, vocab=src_vocab_set)))\n","    print(\"Trg : \", \" \".join(lookup_words(trg_ids, vocab=trg_vocab_set)))\n","    print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab_set)))\n","    print()\n","\n","    if i == n - 1:\n","      break"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l7Hi4X0GJouK","colab_type":"text"},"source":["Here we use the validation dataset to print examples."]},{"cell_type":"code","metadata":{"id":"27thJIfreCgB","colab_type":"code","outputId":"862bda4f-d263-4048-f865-d27399cabfae","executionInfo":{"status":"error","timestamp":1587792665145,"user_tz":240,"elapsed":389,"user":{"displayName":"ByeongJo Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64","userId":"10931837966081205326"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["example_set = MTDataset(val_src_sentences_list, src_vocab_set,\n","                        val_trg_sentences_list, trg_vocab_set)\n","example_data_loader = data.DataLoader(val_set, batch_size=1, num_workers=1,\n","                                      shuffle=False)\n","\n","print_examples(pure_seq2seq, example_data_loader)\n","\n","print(isinstance(attn_seq2seq, EncoderAttentionDecoder))\n","print(type(attn_seq2seq))\n","print(type(pure_seq2seq))\n","print(isinstance(pure_seq2seq, EncoderDecoder))\n","print_examples(attn_seq2seq, example_data_loader)"],"execution_count":5,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-2b61bcd5cdd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m example_set = MTDataset(val_src_sentences_list, src_vocab_set,\n\u001b[0m\u001b[1;32m      2\u001b[0m                         val_trg_sentences_list, trg_vocab_set)\n\u001b[1;32m      3\u001b[0m example_data_loader = data.DataLoader(val_set, batch_size=1, num_workers=1,\n\u001b[1;32m      4\u001b[0m                                       shuffle=False)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'MTDataset' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"H5pTV5PqJtX4","colab_type":"text"},"source":["Compute the BLEU score. BLEU score is a standard measure to evaluate the translation results. For further details, you can refer to [this](https://en.wikipedia.org/wiki/BLEU) link."]},{"cell_type":"code","metadata":{"id":"6XGQYwHRPyne","colab_type":"code","outputId":"fbb75b41-28e9-41ec-df43-b329c56173b4","executionInfo":{"status":"ok","timestamp":1587791932640,"user_tz":240,"elapsed":120967,"user":{"displayName":"ByeongJo Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64","userId":"10931837966081205326"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["import sacrebleu\n","from tqdm import tqdm\n","\n","\n","def compute_BLEU(model, data_loader):\n","  bleu_score = []\n","\n","  model.eval()\n","  for src_ids, src_lengths, trg_ids, _ in tqdm(data_loader):\n","    if isinstance(model, EncoderDecoder):\n","      result = greedy_decode(model, src_ids.to(device), src_lengths.to(device),\n","                             max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS)\n","    elif isinstance(model, EncoderAttentionDecoder):\n","      result, _ = greedy_decode_attention(model, src_ids.to(device),\n","                                          src_lengths.to(device),\n","                                          max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS)\n","    # remove <s>\n","    src_ids = src_ids[0, 1:]\n","    trg_ids = trg_ids[0, 1:]\n","    # remove </s> and <pad>\n","    src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n","    trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n","\n","    pred = \" \".join(lookup_words(result, vocab=trg_vocab_set))\n","    targ = \" \".join(lookup_words(trg_ids, vocab=trg_vocab_set))\n","\n","    bleu_score.append(sacrebleu.raw_corpus_bleu([pred], [[targ]], .01).score)\n","\n","  return bleu_score\n","\n","\n","test_set = MTDataset(test_src_sentences_list, src_vocab_set,\n","                     test_trg_sentences_list, trg_vocab_set, sampling=1.)\n","test_data_loader = data.DataLoader(test_set, batch_size=1, num_workers=8,\n","                                   shuffle=False)\n","\n","print('BLEU score: %f' % (np.mean(compute_BLEU(pure_seq2seq,\n","                                               test_data_loader))))\n","print('BLEU score: %f' % (np.mean(compute_BLEU(attn_seq2seq,\n","                                               test_data_loader))))"],"execution_count":60,"outputs":[{"output_type":"stream","text":["100%|██████████| 1139/1139 [00:51<00:00, 22.26it/s]\n","  0%|          | 0/1139 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["BLEU score: 6.223358\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1139/1139 [01:09<00:00, 16.37it/s]"],"name":"stderr"},{"output_type":"stream","text":["BLEU score: 14.975574\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"aVxViAwwxo6U","colab_type":"text"},"source":["### **Visualizing Attention**"]},{"cell_type":"code","metadata":{"id":"78PgWSbcxmCd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":232},"outputId":"0593486b-fad8-43de-e8ed-840ea8462d58","executionInfo":{"status":"error","timestamp":1587792658656,"user_tz":240,"elapsed":407,"user":{"displayName":"ByeongJo Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64","userId":"10931837966081205326"}}},"source":["def attn_visual(src, trg, scores):\n","  fig, ax = plt.subplots()\n","  attn_map=ax.pcolor(scores,cmap='viridis')\n","  ax.set_xticklabels(trg,minor=False, rotation='vertical')\n","  ax.set_yticklabels(src,minor=False)\n","\n","  ax.xaxis.tick_top()\n","  ax.set_xticklabels(np.arrange(scores.shape[1])+0.5, minor=False)\n","  ax.set_yticklabels(np.arrange(scores.shape[0])+0.5, minor=False)\n","  ax.invert_yaxis()\n","\n","  plt.colorbar(attn_map)\n","  plt.show()\n","\n","idx=5\n","src=valid_data[idx].src+[\"</s>\"]\n","trg=valid_data[idx].trg+[\"</s>\"]\n","pred=hypotheses[idx].split()+[\"</s>\"]\n","pred_attn=alphas[idx][0].T[:,:len(pred)]\n","print(\"src\",src)\n","print(\"ref\",trg)\n","print(\"pred\",pred)\n","attn_visual(src,pred,pred_attn)"],"execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-7c589ca550e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"</s>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"</s>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhypotheses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"</s>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'valid_data' is not defined"]}]},{"cell_type":"code","metadata":{"id":"LiJMHzZ80G62","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":164},"outputId":"908f49c8-3991-478b-f357-af2e0745f624","executionInfo":{"status":"error","timestamp":1587792631605,"user_tz":240,"elapsed":463,"user":{"displayName":"ByeongJo Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjB3OJt2FV1VBgbxRHjhh6mK4NBkVW9ONJVSMVJ=s64","userId":"10931837966081205326"}}},"source":["next(iter(val_data))"],"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-78070b20a540>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'val_data' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"GbOgwJw_CkCW","colab_type":"text"},"source":["## **Part 3: Lab writeup**\n","\n","Your lab report should discuss any implementation details that were important to filling out the code above. Then, use the code to set up experiments that answer the following questions:\n","\n","1. In this lab we use greedy search for decoding, that is, always taking the most probable word at current timestep as prediction. Describe an alternative decoding method that might work better than greedy search. You don't have to implement it.\n","\n","2. Pick some samples from dev or test set and visualize their attention maps. Discuss your findings. Hint: compute the attention scores on the input words for each timestep during decoding.\n","\n","3. Compare the performance of seq2seq with and without attention on sentences of different lengths. You can set some length intervals (e.g., 1-10, 11-20, 21-30, 31-40, 41-50) and compare the two models' performance within each length interval. Discuss your findings.\n","\n","4. Try to improve your BLEU score. For example, try stacking more RNN layers, switching cell types, or applying bi-direction to encoder. Describe what you try, even if they don't show improvement. Hints:\n","  * TA's preliminary implemtation of seq2seq with attention model achieves around 16. You don't have to surpass it (although it's pretty simple to do so)--this number is just to give you some sense of what a baseline should get.\n","  * Training on the entire training set takes some time. So tune your hyperparameters on a smaller training set (you can do so by changing `sampling` when creating the data loader)."]}]}